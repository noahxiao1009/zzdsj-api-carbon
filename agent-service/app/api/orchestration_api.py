"""
æ™ºèƒ½ä½“ç¼–æ’API - å¯¹åº”å‰ç«¯ç”»å¸ƒç¼–æ’åŠŸèƒ½
åŸºäºå‰ç«¯FlowDesignerå’ŒAgentBuilderçš„éœ€æ±‚å®ç°
"""
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Query
from fastapi.responses import StreamingResponse
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
import logging
import json
import asyncio
from datetime import datetime
from enum import Enum

from ..core.dag_orchestrator import dag_orchestrator
from ..core.agno_manager import agno_manager
from ..core.workflow_v2_manager import workflow_v2_manager
from ..schemas.flow_builder_schemas import (
    BaseDataResponse, 
    ExecutionStatus,
    StreamingMessage
)
from ..schemas.workflow_v2_schemas import (
    WorkflowV2Config,
    WorkflowV2ExecutionRequest,
    WorkflowV2ExecutionResult,
    WorkflowV2CodeGenerationRequest,
    WorkflowV2CodeGenerationResult,
    WorkflowV2ListRequest,
    WorkflowV2ListResponse,
    WorkflowV2Summary,
    WorkflowV2CreateResponse,
    WorkflowV2DetailResponse,
    WorkflowV2ExecutionResponse,
    WorkflowV2CodeResponse,
    WorkflowV2StreamingResponse,
    WorkflowExecutionMode
)

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/v1/orchestration", tags=["orchestration"])

# ç”»å¸ƒç¼–æ’ç›¸å…³Schema
class NodeType(str, Enum):
    """èŠ‚ç‚¹ç±»å‹"""
    MODEL = "model"
    TOOL = "tool"
    AGENT = "agent"
    CONDITION = "condition"
    OUTPUT = "output"
    INPUT = "input"
    KNOWLEDGE = "knowledge"

class ConnectionType(str, Enum):
    """è¿æ¥ç±»å‹"""
    SEQUENCE = "sequence"
    PARALLEL = "parallel"
    CONDITIONAL = "conditional"
    LOOP = "loop"

class FlowNode(BaseModel):
    """æµç¨‹èŠ‚ç‚¹"""
    id: str = Field(..., description="èŠ‚ç‚¹ID")
    type: NodeType = Field(..., description="èŠ‚ç‚¹ç±»å‹")
    name: str = Field(..., description="èŠ‚ç‚¹åç§°")
    description: str = Field("", description="èŠ‚ç‚¹æè¿°")
    position: Dict[str, float] = Field(..., description="èŠ‚ç‚¹ä½ç½®åæ ‡")
    config: Dict[str, Any] = Field(default_factory=dict, description="èŠ‚ç‚¹é…ç½®")
    
    # æ‰©å±•å±æ€§
    enabled: bool = Field(True, description="èŠ‚ç‚¹æ˜¯å¦å¯ç”¨")
    timeout: int = Field(60, description="èŠ‚ç‚¹è¶…æ—¶æ—¶é—´(ç§’)")
    retry_count: int = Field(3, description="é‡è¯•æ¬¡æ•°")

class FlowConnection(BaseModel):
    """æµç¨‹è¿æ¥"""
    id: str = Field(..., description="è¿æ¥ID")
    source: str = Field(..., description="æºèŠ‚ç‚¹ID")
    target: str = Field(..., description="ç›®æ ‡èŠ‚ç‚¹ID")
    type: ConnectionType = Field(ConnectionType.SEQUENCE, description="è¿æ¥ç±»å‹")
    condition: Optional[str] = Field(None, description="æ¡ä»¶è¡¨è¾¾å¼")
    label: Optional[str] = Field(None, description="è¿æ¥æ ‡ç­¾")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="è¿æ¥å…ƒæ•°æ®")

class FlowDefinition(BaseModel):
    """æµç¨‹å®šä¹‰"""
    id: str = Field(..., description="æµç¨‹ID")
    name: str = Field(..., description="æµç¨‹åç§°")
    description: str = Field("", description="æµç¨‹æè¿°")
    version: str = Field("1.0", description="ç‰ˆæœ¬å·")
    
    # æ ¸å¿ƒç»“æ„
    nodes: List[FlowNode] = Field(..., description="èŠ‚ç‚¹åˆ—è¡¨")
    connections: List[FlowConnection] = Field(..., description="è¿æ¥åˆ—è¡¨")
    
    # å…¨å±€é…ç½®
    variables: Dict[str, Any] = Field(default_factory=dict, description="å…¨å±€å˜é‡")
    timeout: int = Field(300, description="æ€»è¶…æ—¶æ—¶é—´(ç§’)")
    
    # å…ƒæ•°æ®
    tags: List[str] = Field(default_factory=list, description="æ ‡ç­¾")
    created_by: Optional[str] = Field(None, description="åˆ›å»ºè€…")
    created_at: datetime = Field(default_factory=datetime.now, description="åˆ›å»ºæ—¶é—´")
    updated_at: datetime = Field(default_factory=datetime.now, description="æ›´æ–°æ—¶é—´")

class FlowExecutionRequest(BaseModel):
    """æµç¨‹æ‰§è¡Œè¯·æ±‚"""
    flow_id: str = Field(..., description="æµç¨‹ID")
    input_data: Dict[str, Any] = Field(default_factory=dict, description="è¾“å…¥æ•°æ®")
    variables: Dict[str, Any] = Field(default_factory=dict, description="å˜é‡è¦†ç›–")
    stream: bool = Field(False, description="æ˜¯å¦æµå¼æ‰§è¡Œ")
    
    # æ‰§è¡Œé€‰é¡¹
    timeout: Optional[int] = Field(None, description="è¶…æ—¶æ—¶é—´è¦†ç›–")
    debug: bool = Field(False, description="è°ƒè¯•æ¨¡å¼")
    track_metrics: bool = Field(True, description="æ˜¯å¦è·Ÿè¸ªæŒ‡æ ‡")

class FlowExecutionStatus(BaseModel):
    """æµç¨‹æ‰§è¡ŒçŠ¶æ€"""
    execution_id: str
    flow_id: str
    status: ExecutionStatus
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    
    # æ‰§è¡Œè·¯å¾„
    execution_path: List[str] = Field(default_factory=list)
    current_node: Optional[str] = None
    
    # èŠ‚ç‚¹çŠ¶æ€
    node_statuses: Dict[str, str] = Field(default_factory=dict)
    node_results: Dict[str, Any] = Field(default_factory=dict)
    
    # ç»“æœå’Œé”™è¯¯
    final_result: Optional[Any] = None
    error_message: Optional[str] = None
    
    # æ€§èƒ½æŒ‡æ ‡
    execution_time: Optional[float] = None
    total_nodes: int = 0
    completed_nodes: int = 0
    progress_percentage: float = 0.0

class NodeTemplate(BaseModel):
    """èŠ‚ç‚¹æ¨¡æ¿"""
    id: str
    type: NodeType
    name: str
    description: str
    category: str
    icon: str
    
    # é…ç½®Schema
    config_schema: Dict[str, Any] = Field(default_factory=dict)
    default_config: Dict[str, Any] = Field(default_factory=dict)
    
    # è¿æ¥ç‚¹
    input_ports: List[str] = Field(default_factory=list)
    output_ports: List[str] = Field(default_factory=list)
    
    # æ‰©å±•å±æ€§
    color: str = "#64748b"
    requires_auth: bool = False
    estimated_cost: str = "low"

# ä¾èµ–å‡½æ•°
async def get_current_user_id() -> str:
    """è·å–å½“å‰ç”¨æˆ·ID"""
    return "user_123"

# ç”»å¸ƒç¼–æ’API
@router.get("/node-templates", response_model=BaseDataResponse)
async def get_node_templates():
    """è·å–èŠ‚ç‚¹æ¨¡æ¿åˆ—è¡¨"""
    try:
        templates = [
            NodeTemplate(
                id="llm_node",
                type=NodeType.MODEL,
                name="å¤§è¯­è¨€æ¨¡å‹",
                description="è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ",
                category="model",
                icon="ğŸ¤–",
                config_schema={
                    "model_name": {"type": "select", "options": ["claude-3-5-sonnet", "gpt-4o"], "required": True},
                    "temperature": {"type": "slider", "min": 0, "max": 2, "step": 0.1},
                    "max_tokens": {"type": "number", "min": 1, "max": 4000}
                },
                default_config={
                    "model_name": "claude-3-5-sonnet",
                    "temperature": 0.7,
                    "max_tokens": 1000
                },
                input_ports=["prompt"],
                output_ports=["response"],
                color="#6366f1"
            ),
            NodeTemplate(
                id="knowledge_search",
                type=NodeType.TOOL,
                name="çŸ¥è¯†åº“æ£€ç´¢",
                description="åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯",
                category="knowledge",
                icon="ğŸ”",
                config_schema={
                    "knowledge_base_id": {"type": "select", "required": True},
                    "top_k": {"type": "number", "min": 1, "max": 20},
                    "similarity_threshold": {"type": "slider", "min": 0, "max": 1, "step": 0.01}
                },
                default_config={
                    "top_k": 5,
                    "similarity_threshold": 0.7
                },
                input_ports=["query"],
                output_ports=["results"],
                color="#10b981"
            ),
            NodeTemplate(
                id="web_search",
                type=NodeType.TOOL,
                name="ç½‘ç»œæœç´¢",
                description="æœç´¢äº’è”ç½‘ä¿¡æ¯",
                category="search",
                icon="ğŸŒ",
                config_schema={
                    "search_engine": {"type": "select", "options": ["google", "bing"], "required": True},
                    "max_results": {"type": "number", "min": 1, "max": 10}
                },
                default_config={
                    "search_engine": "google",
                    "max_results": 5
                },
                input_ports=["query"],
                output_ports=["results"],
                color="#f59e0b"
            ),
            NodeTemplate(
                id="condition_node",
                type=NodeType.CONDITION,
                name="æ¡ä»¶åˆ¤æ–­",
                description="æ ¹æ®æ¡ä»¶å†³å®šæ‰§è¡Œè·¯å¾„",
                category="logic",
                icon="âš¡",
                config_schema={
                    "condition": {"type": "text", "required": True},
                    "operator": {"type": "select", "options": ["==", "!=", ">", "<", ">=", "<=", "contains"]}
                },
                default_config={
                    "operator": "=="
                },
                input_ports=["input"],
                output_ports=["true", "false"],
                color="#8b5cf6"
            ),
            NodeTemplate(
                id="output_node",
                type=NodeType.OUTPUT,
                name="è¾“å‡ºèŠ‚ç‚¹",
                description="è¾“å‡ºæœ€ç»ˆç»“æœ",
                category="output",
                icon="ğŸ“¤",
                config_schema={
                    "format": {"type": "select", "options": ["text", "json", "markdown"]},
                    "template": {"type": "textarea"}
                },
                default_config={
                    "format": "text"
                },
                input_ports=["data"],
                output_ports=[],
                color="#ef4444"
            ),
            NodeTemplate(
                id="agent_node",
                type=NodeType.AGENT,
                name="æ™ºèƒ½ä½“",
                description="è°ƒç”¨é¢„å®šä¹‰çš„æ™ºèƒ½ä½“",
                category="agent",
                icon="ğŸ¤–",
                config_schema={
                    "agent_id": {"type": "select", "required": True},
                    "context": {"type": "textarea"}
                },
                default_config={},
                input_ports=["message"],
                output_ports=["response"],
                color="#ec4899"
            )
        ]
        
        return BaseDataResponse(
            success=True,
            data=templates,
            message="Successfully retrieved node templates"
        )
        
    except Exception as e:
        logger.error(f"Failed to get node templates: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/flows", response_model=BaseDataResponse)
async def create_flow(
    flow: FlowDefinition,
    user_id: str = Depends(get_current_user_id)
):
    """åˆ›å»ºæ–°çš„æµç¨‹"""
    try:
        # éªŒè¯æµç¨‹ç»“æ„
        _validate_flow_structure(flow)
        
        # è®¾ç½®åˆ›å»ºè€…
        flow.created_by = user_id
        flow.created_at = datetime.now()
        flow.updated_at = datetime.now()
        
        # ä¿å­˜æµç¨‹å®šä¹‰ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºå†…å­˜å­˜å‚¨ï¼‰
        if not hasattr(dag_orchestrator, 'flow_definitions'):
            dag_orchestrator.flow_definitions = {}
        
        dag_orchestrator.flow_definitions[flow.id] = flow
        
        logger.info(f"Created flow {flow.id} by user {user_id}")
        
        return BaseDataResponse(
            success=True,
            data=flow.dict(),
            message="Flow created successfully"
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Failed to create flow: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/flows/{flow_id}", response_model=BaseDataResponse)
async def get_flow(flow_id: str):
    """è·å–æµç¨‹å®šä¹‰"""
    try:
        if not hasattr(dag_orchestrator, 'flow_definitions'):
            dag_orchestrator.flow_definitions = {}
        
        if flow_id not in dag_orchestrator.flow_definitions:
            raise HTTPException(status_code=404, detail="Flow not found")
        
        flow = dag_orchestrator.flow_definitions[flow_id]
        
        return BaseDataResponse(
            success=True,
            data=flow.dict(),
            message="Successfully retrieved flow"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get flow: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.put("/flows/{flow_id}", response_model=BaseDataResponse)
async def update_flow(
    flow_id: str,
    flow: FlowDefinition,
    user_id: str = Depends(get_current_user_id)
):
    """æ›´æ–°æµç¨‹å®šä¹‰"""
    try:
        if not hasattr(dag_orchestrator, 'flow_definitions'):
            dag_orchestrator.flow_definitions = {}
        
        if flow_id not in dag_orchestrator.flow_definitions:
            raise HTTPException(status_code=404, detail="Flow not found")
        
        # éªŒè¯æµç¨‹ç»“æ„
        _validate_flow_structure(flow)
        
        # æ›´æ–°æ—¶é—´
        flow.updated_at = datetime.now()
        flow.id = flow_id  # ç¡®ä¿IDä¸€è‡´
        
        # ä¿å­˜æ›´æ–°
        dag_orchestrator.flow_definitions[flow_id] = flow
        
        logger.info(f"Updated flow {flow_id} by user {user_id}")
        
        return BaseDataResponse(
            success=True,
            data=flow.dict(),
            message="Flow updated successfully"
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to update flow: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/flows/{flow_id}")
async def delete_flow(
    flow_id: str,
    user_id: str = Depends(get_current_user_id)
):
    """åˆ é™¤æµç¨‹"""
    try:
        if not hasattr(dag_orchestrator, 'flow_definitions'):
            dag_orchestrator.flow_definitions = {}
        
        if flow_id not in dag_orchestrator.flow_definitions:
            raise HTTPException(status_code=404, detail="Flow not found")
        
        # åˆ é™¤æµç¨‹
        del dag_orchestrator.flow_definitions[flow_id]
        
        logger.info(f"Deleted flow {flow_id} by user {user_id}")
        
        return BaseDataResponse(
            success=True,
            data=None,
            message="Flow deleted successfully"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to delete flow: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/flows", response_model=BaseDataResponse)
async def list_flows(
    user_id: str = Depends(get_current_user_id),
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100)
):
    """è·å–æµç¨‹åˆ—è¡¨"""
    try:
        if not hasattr(dag_orchestrator, 'flow_definitions'):
            dag_orchestrator.flow_definitions = {}
        
        flows = list(dag_orchestrator.flow_definitions.values())
        
        # åˆ†é¡µ
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        paginated_flows = flows[start_idx:end_idx]
        
        # ç®€åŒ–å“åº”æ•°æ®
        flow_summaries = []
        for flow in paginated_flows:
            summary = {
                "id": flow.id,
                "name": flow.name,
                "description": flow.description,
                "version": flow.version,
                "node_count": len(flow.nodes),
                "connection_count": len(flow.connections),
                "tags": flow.tags,
                "created_by": flow.created_by,
                "created_at": flow.created_at.isoformat(),
                "updated_at": flow.updated_at.isoformat()
            }
            flow_summaries.append(summary)
        
        return BaseDataResponse(
            success=True,
            data={
                "flows": flow_summaries,
                "pagination": {
                    "page": page,
                    "page_size": page_size,
                    "total": len(flows),
                    "total_pages": (len(flows) + page_size - 1) // page_size
                }
            },
            message="Successfully retrieved flows"
        )
        
    except Exception as e:
        logger.error(f"Failed to list flows: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/flows/{flow_id}/execute", response_model=BaseDataResponse)
async def execute_flow(
    flow_id: str,
    request: FlowExecutionRequest,
    background_tasks: BackgroundTasks,
    user_id: str = Depends(get_current_user_id)
):
    """æ‰§è¡Œæµç¨‹"""
    try:
        if not hasattr(dag_orchestrator, 'flow_definitions'):
            dag_orchestrator.flow_definitions = {}
        
        if flow_id not in dag_orchestrator.flow_definitions:
            raise HTTPException(status_code=404, detail="Flow not found")
        
        flow = dag_orchestrator.flow_definitions[flow_id]
        
        # åˆ›å»ºæ‰§è¡Œå®ä¾‹
        execution_id = f"exec_{flow_id}_{int(datetime.now().timestamp())}"
        
        # è½¬æ¢ä¸ºDAGæ‰§è¡Œæ ¼å¼
        dag_template = _convert_flow_to_dag_template(flow)
        
        # åˆ›å»ºæ‰§è¡Œ
        execution = await dag_orchestrator.create_execution(
            template_id=f"flow_{flow_id}",
            user_id=user_id,
            input_data=request.input_data,
            config_overrides=request.variables,
            custom_template=dag_template
        )
        
        if request.stream:
            # åå°æ‰§è¡Œ
            background_tasks.add_task(_execute_flow_background, execution_id, flow_id)
            
            return BaseDataResponse(
                success=True,
                data={
                    "execution_id": execution_id,
                    "flow_id": flow_id,
                    "status": "started",
                    "stream": True,
                    "stream_url": f"/api/v1/orchestration/executions/{execution_id}/stream"
                },
                message="Flow execution started"
            )
        else:
            # åŒæ­¥æ‰§è¡Œ
            result = await dag_orchestrator.execute_dag(execution)
            
            status = FlowExecutionStatus(
                execution_id=execution_id,
                flow_id=flow_id,
                status=result.status,
                start_time=result.start_time,
                end_time=result.end_time,
                execution_path=result.execution_path,
                node_statuses=result.node_statuses,
                node_results=result.node_results,
                final_result=result.final_result,
                execution_time=(result.end_time - result.start_time).total_seconds() if result.end_time and result.start_time else None,
                total_nodes=len(flow.nodes),
                completed_nodes=len([s for s in result.node_statuses.values() if s == "completed"]),
                progress_percentage=100.0 if result.status == ExecutionStatus.COMPLETED else 0.0
            )
            
            return BaseDataResponse(
                success=True,
                data=status.dict(),
                message="Flow execution completed"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to execute flow: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/executions/{execution_id}/status", response_model=BaseDataResponse)
async def get_execution_status(execution_id: str):
    """è·å–æ‰§è¡ŒçŠ¶æ€"""
    try:
        if execution_id not in dag_orchestrator.executions:
            raise HTTPException(status_code=404, detail="Execution not found")
        
        execution = dag_orchestrator.executions[execution_id]
        
        # è®¡ç®—è¿›åº¦
        total_nodes = len(execution.template.nodes) if hasattr(execution, 'template') else 0
        completed_nodes = len([s for s in execution.node_statuses.values() if s == "completed"])
        progress = (completed_nodes / total_nodes * 100) if total_nodes > 0 else 0
        
        status = FlowExecutionStatus(
            execution_id=execution_id,
            flow_id=getattr(execution, 'flow_id', 'unknown'),
            status=execution.status,
            start_time=execution.start_time,
            end_time=execution.end_time,
            execution_path=execution.execution_path,
            current_node=execution.current_node if hasattr(execution, 'current_node') else None,
            node_statuses=execution.node_statuses,
            node_results=execution.node_results,
            final_result=execution.final_result,
            error_message=execution.error_message if hasattr(execution, 'error_message') else None,
            execution_time=(execution.end_time - execution.start_time).total_seconds() if execution.end_time and execution.start_time else None,
            total_nodes=total_nodes,
            completed_nodes=completed_nodes,
            progress_percentage=progress
        )
        
        return BaseDataResponse(
            success=True,
            data=status.dict(),
            message="Successfully retrieved execution status"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get execution status: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/executions/{execution_id}/stream")
async def stream_execution_results(execution_id: str):
    """æµå¼è·å–æ‰§è¡Œç»“æœ"""
    async def generate_stream():
        try:
            if execution_id not in dag_orchestrator.executions:
                yield f"data: {json.dumps({'type': 'error', 'error': 'Execution not found'})}\n\n"
                return
            
            execution = dag_orchestrator.executions[execution_id]
            
            # å‘é€åˆå§‹çŠ¶æ€
            yield f"data: {json.dumps({'type': 'status', 'status': execution.status.value})}\n\n"
            
            # ç›‘æ§æ‰§è¡Œè¿‡ç¨‹
            last_path_length = 0
            
            while execution.status in [ExecutionStatus.PENDING, ExecutionStatus.RUNNING]:
                # æ£€æŸ¥æ‰§è¡Œè·¯å¾„æ›´æ–°
                if len(execution.execution_path) > last_path_length:
                    new_nodes = execution.execution_path[last_path_length:]
                    for node_id in new_nodes:
                        message = StreamingMessage(
                            type="node_started",
                            data={"node_id": node_id}
                        )
                        yield f"data: {json.dumps(message.dict())}\n\n"
                    last_path_length = len(execution.execution_path)
                
                # æ£€æŸ¥èŠ‚ç‚¹å®Œæˆ
                for node_id, status in execution.node_statuses.items():
                    if status == "completed" and node_id in execution.node_results:
                        message = StreamingMessage(
                            type="node_completed",
                            data={
                                "node_id": node_id,
                                "result": execution.node_results[node_id]
                            }
                        )
                        yield f"data: {json.dumps(message.dict())}\n\n"
                
                await asyncio.sleep(0.5)
            
            # å‘é€æœ€ç»ˆç»“æœ
            final_message = StreamingMessage(
                type="final_result",
                data={
                    "status": execution.status.value,
                    "result": execution.final_result,
                    "execution_path": execution.execution_path
                }
            )
            yield f"data: {json.dumps(final_message.dict())}\n\n"
            
        except Exception as e:
            error_message = StreamingMessage(
                type="error",
                data={"error": str(e)}
            )
            yield f"data: {json.dumps(error_message.dict())}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

# è¾…åŠ©å‡½æ•°
def _validate_flow_structure(flow: FlowDefinition):
    """éªŒè¯æµç¨‹ç»“æ„"""
    if not flow.nodes:
        raise ValueError("Flow must have at least one node")
    
    node_ids = {node.id for node in flow.nodes}
    
    # éªŒè¯è¿æ¥
    for conn in flow.connections:
        if conn.source not in node_ids:
            raise ValueError(f"Connection source node {conn.source} not found")
        if conn.target not in node_ids:
            raise ValueError(f"Connection target node {conn.target} not found")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥å’Œè¾“å‡ºèŠ‚ç‚¹
    has_input = any(node.type == NodeType.INPUT for node in flow.nodes)
    has_output = any(node.type == NodeType.OUTPUT for node in flow.nodes)
    
    if not has_input and not has_output:
        logger.warning(f"Flow {flow.id} has no input or output nodes")

def _convert_flow_to_dag_template(flow: FlowDefinition) -> Dict[str, Any]:
    """å°†æµç¨‹å®šä¹‰è½¬æ¢ä¸ºDAGæ¨¡æ¿"""
    # ç®€åŒ–çš„è½¬æ¢é€»è¾‘
    nodes = []
    edges = []
    
    for node in flow.nodes:
        dag_node = {
            "id": node.id,
            "type": node.type.value,
            "name": node.name,
            "description": node.description,
            "config": node.config,
            "dependencies": [],
            "dependents": []
        }
        nodes.append(dag_node)
    
    for conn in flow.connections:
        edge = {
            "from_node": conn.source,
            "to_node": conn.target,
            "condition": conn.condition,
            "metadata": conn.metadata
        }
        edges.append(edge)
    
    return {
        "template_id": f"flow_{flow.id}",
        "name": flow.name,
        "description": flow.description,
        "nodes": nodes,
        "edges": edges,
        "variables": flow.variables,
        "version": flow.version
    }

async def _execute_flow_background(execution_id: str, flow_id: str):
    """åå°æ‰§è¡Œæµç¨‹"""
    try:
        await dag_orchestrator.execute_dag(execution_id)
    except Exception as e:
        logger.error(f"Background flow execution failed: {str(e)}")


# ====================== Workflow v2 API Routes ======================

def _get_current_user_id() -> str:
    """è·å–å½“å‰ç”¨æˆ·IDï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
    # TODO: ä»JWT tokenæˆ–sessionä¸­è·å–çœŸå®ç”¨æˆ·ID
    return "system_user"


@router.post("/workflows-v2", response_model=WorkflowV2CreateResponse, tags=["workflow-v2"])
async def create_workflow_v2(
    config: WorkflowV2Config,
    user_id: str = Depends(_get_current_user_id)
):
    """
    åˆ›å»ºWorkflow v2å·¥ä½œæµ
    
    åŸºäºç¡…åŸºæµåŠ¨APIçš„æ–°ä¸€ä»£å·¥ä½œæµç³»ç»Ÿï¼Œæ”¯æŒï¼š
    - çº¯Pythoné…ç½®å¼å·¥ä½œæµ
    - ç¡…åŸºæµåŠ¨æ¨¡å‹é›†æˆ
    - æ™ºèƒ½ä½“åä½œç¼–æ’
    - å®æ—¶ä»£ç ç”Ÿæˆ
    """
    try:
        logger.info(f"Creating Workflow v2: {config.name} by user {user_id}")
        
        # ç¡®ä¿workflow_v2_managerå·²åˆå§‹åŒ–
        if not workflow_v2_manager._initialized:
            await workflow_v2_manager.initialize()
        
        # åˆ›å»ºå·¥ä½œæµ
        workflow_id = await workflow_v2_manager.create_workflow_from_config(config)
        
        logger.info(f"Workflow v2 created successfully: {workflow_id}")
        
        return WorkflowV2CreateResponse(
            success=True,
            message="å·¥ä½œæµåˆ›å»ºæˆåŠŸ",
            data={
                "workflow_id": workflow_id,
                "message": f"å·¥ä½œæµ '{config.name}' åˆ›å»ºæˆåŠŸï¼Œä½¿ç”¨ç¡…åŸºæµåŠ¨API"
            }
        )
        
    except ValueError as e:
        logger.error(f"Workflow v2 creation validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Workflow v2 creation failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå·¥ä½œæµå¤±è´¥: {str(e)}")


@router.get("/workflows-v2/{workflow_id}", response_model=WorkflowV2DetailResponse, tags=["workflow-v2"])
async def get_workflow_v2(
    workflow_id: str,
    user_id: str = Depends(_get_current_user_id)
):
    """
    è·å–Workflow v2å·¥ä½œæµè¯¦æƒ…
    """
    try:
        logger.info(f"Getting Workflow v2 details: {workflow_id}")
        
        config = await workflow_v2_manager.get_workflow_config(workflow_id)
        if not config:
            raise HTTPException(status_code=404, detail=f"å·¥ä½œæµ {workflow_id} ä¸å­˜åœ¨")
        
        return WorkflowV2DetailResponse(
            success=True,
            message="è·å–å·¥ä½œæµè¯¦æƒ…æˆåŠŸ",
            data=config
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Get Workflow v2 failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµè¯¦æƒ…å¤±è´¥: {str(e)}")


@router.put("/workflows-v2/{workflow_id}", response_model=WorkflowV2DetailResponse, tags=["workflow-v2"])
async def update_workflow_v2(
    workflow_id: str,
    updates: Dict[str, Any],
    user_id: str = Depends(_get_current_user_id)
):
    """
    æ›´æ–°Workflow v2å·¥ä½œæµé…ç½®
    """
    try:
        logger.info(f"Updating Workflow v2: {workflow_id}")
        
        updated_config = await workflow_v2_manager.update_workflow_config(workflow_id, updates)
        
        return WorkflowV2DetailResponse(
            success=True,
            message="å·¥ä½œæµæ›´æ–°æˆåŠŸ",
            data=updated_config
        )
        
    except ValueError as e:
        logger.error(f"Workflow v2 update validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Update Workflow v2 failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å·¥ä½œæµå¤±è´¥: {str(e)}")


@router.delete("/workflows-v2/{workflow_id}", response_model=BaseDataResponse, tags=["workflow-v2"])
async def delete_workflow_v2(
    workflow_id: str,
    user_id: str = Depends(_get_current_user_id)
):
    """
    åˆ é™¤Workflow v2å·¥ä½œæµ
    """
    try:
        logger.info(f"Deleting Workflow v2: {workflow_id}")
        
        result = await workflow_v2_manager.delete_workflow(workflow_id)
        if not result:
            raise HTTPException(status_code=404, detail=f"å·¥ä½œæµ {workflow_id} ä¸å­˜åœ¨")
        
        return BaseDataResponse(
            success=True,
            message="å·¥ä½œæµåˆ é™¤æˆåŠŸ",
            data={"workflow_id": workflow_id}
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Delete Workflow v2 failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å·¥ä½œæµå¤±è´¥: {str(e)}")


@router.get("/workflows-v2", response_model=WorkflowV2ListResponse, tags=["workflow-v2"])
async def list_workflows_v2(
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(20, ge=1, le=100, description="æ¯é¡µå¤§å°"),
    category: Optional[str] = Query(None, description="åˆ†ç±»ç­›é€‰"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
    user_id: str = Depends(_get_current_user_id)
):
    """
    è·å–Workflow v2å·¥ä½œæµåˆ—è¡¨
    """
    try:
        logger.info(f"Listing Workflow v2s - page: {page}, size: {size}")
        
        workflows = await workflow_v2_manager.list_workflows()
        
        # ç®€å•çš„æœç´¢è¿‡æ»¤
        if search:
            search_lower = search.lower()
            workflows = [
                w for w in workflows 
                if search_lower in w.name.lower() or search_lower in w.description.lower()
            ]
        
        # åˆ†ç±»è¿‡æ»¤
        if category:
            workflows = [w for w in workflows if w.category == category]
        
        # åˆ†é¡µ
        total = len(workflows)
        start_idx = (page - 1) * size
        end_idx = start_idx + size
        paginated_workflows = workflows[start_idx:end_idx]
        
        # è½¬æ¢ä¸ºæ‘˜è¦æ ¼å¼
        workflow_summaries = []
        for w in paginated_workflows:
            summary = WorkflowV2Summary(
                id=w.id or "",
                name=w.name,
                description=w.description,
                version=w.version,
                category=w.category,
                tags=w.tags,
                agent_count=len(w.components.agents),
                step_count=len(w.logic.steps),
                status="active",
                created_at=w.created_at,
                updated_at=w.updated_at
            )
            workflow_summaries.append(summary.dict())
        
        pages = (total + size - 1) // size
        
        return WorkflowV2ListResponse(
            success=True,
            message="è·å–å·¥ä½œæµåˆ—è¡¨æˆåŠŸ",
            data={
                "workflows": workflow_summaries,
                "total": total,
                "page": page,
                "size": size,
                "pages": pages
            }
        )
        
    except Exception as e:
        logger.error(f"List Workflow v2s failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµåˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/workflows-v2/{workflow_id}/execute", response_model=WorkflowV2ExecutionResponse, tags=["workflow-v2"])
async def execute_workflow_v2(
    workflow_id: str,
    request: WorkflowV2ExecutionRequest,
    user_id: str = Depends(_get_current_user_id)
):
    """
    æ‰§è¡ŒWorkflow v2å·¥ä½œæµ
    
    æ”¯æŒåŒæ­¥ã€å¼‚æ­¥å’Œæµå¼æ‰§è¡Œæ¨¡å¼
    """
    try:
        logger.info(f"Executing Workflow v2: {workflow_id} with mode: {request.execution_mode}")
        
        # æ‰§è¡Œå·¥ä½œæµ
        result = await workflow_v2_manager.execute_workflow(
            workflow_id=workflow_id,
            input_data=request.input_data,
            stream=request.stream
        )
        
        return WorkflowV2ExecutionResponse(
            success=True,
            message="å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ",
            data=result
        )
        
    except ValueError as e:
        logger.error(f"Workflow v2 execution validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Execute Workflow v2 failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå·¥ä½œæµå¤±è´¥: {str(e)}")


@router.get("/workflows-v2/{workflow_id}/execute/{execution_id}", response_model=WorkflowV2ExecutionResponse, tags=["workflow-v2"])
async def get_execution_result_v2(
    workflow_id: str,
    execution_id: str,
    user_id: str = Depends(_get_current_user_id)
):
    """
    è·å–Workflow v2æ‰§è¡Œç»“æœ
    """
    try:
        logger.info(f"Getting execution result: {execution_id}")
        
        # ä»ç®¡ç†å™¨ä¸­è·å–æ‰§è¡Œç»“æœ
        result = workflow_v2_manager.execution_results.get(execution_id)
        if not result:
            raise HTTPException(status_code=404, detail=f"æ‰§è¡Œè®°å½• {execution_id} ä¸å­˜åœ¨")
        
        return WorkflowV2ExecutionResponse(
            success=True,
            message="è·å–æ‰§è¡Œç»“æœæˆåŠŸ",
            data=result
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Get execution result failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ‰§è¡Œç»“æœå¤±è´¥: {str(e)}")


@router.get("/workflows-v2/{workflow_id}/execute/{execution_id}/stream", tags=["workflow-v2"])
async def stream_execution_v2(
    workflow_id: str,
    execution_id: str,
    user_id: str = Depends(_get_current_user_id)
):
    """
    æµå¼è·å–Workflow v2æ‰§è¡Œè¿‡ç¨‹
    """
    async def generate_stream():
        """ç”Ÿæˆæ‰§è¡Œæµæ•°æ®"""
        try:
            # æ¨¡æ‹Ÿæµå¼è¾“å‡º
            yield f"data: {json.dumps({'event_type': 'execution_start', 'execution_id': execution_id, 'timestamp': datetime.now().isoformat()})}\n\n"
            
            # è·å–æ‰§è¡Œç»“æœ
            result = workflow_v2_manager.execution_results.get(execution_id)
            if result:
                # è¾“å‡ºæ­¥éª¤ç»“æœ
                for step_id, step_result in result.steps_results.items():
                    yield f"data: {json.dumps({'event_type': 'step_completed', 'step_id': step_id, 'result': str(step_result), 'timestamp': datetime.now().isoformat()})}\n\n"
                
                # è¾“å‡ºæœ€ç»ˆç»“æœ
                yield f"data: {json.dumps({'event_type': 'execution_completed', 'status': result.status, 'result': str(result.result), 'timestamp': datetime.now().isoformat()})}\n\n"
            else:
                yield f"data: {json.dumps({'event_type': 'error', 'message': 'Execution not found', 'timestamp': datetime.now().isoformat()})}\n\n"
            
            yield "data: [DONE]\n\n"
            
        except Exception as e:
            logger.error(f"Stream execution failed: {str(e)}")
            yield f"data: {json.dumps({'event_type': 'error', 'message': str(e), 'timestamp': datetime.now().isoformat()})}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )


@router.get("/workflows-v2/{workflow_id}/code", response_model=WorkflowV2CodeResponse, tags=["workflow-v2"])
async def get_workflow_code_v2(
    workflow_id: str,
    include_comments: bool = Query(True, description="æ˜¯å¦åŒ…å«æ³¨é‡Š"),
    user_id: str = Depends(_get_current_user_id)
):
    """
    è·å–Workflow v2ç”Ÿæˆçš„Pythonä»£ç 
    """
    try:
        logger.info(f"Getting Workflow v2 code: {workflow_id}")
        
        # ç”ŸæˆPythonä»£ç 
        python_code = await workflow_v2_manager.generate_workflow_code(workflow_id)
        
        # éªŒè¯ä»£ç 
        validation_result = workflow_v2_manager.code_generator.validate_generated_code(python_code)
        
        result = WorkflowV2CodeGenerationResult(
            workflow_id=workflow_id,
            generated_code=python_code,
            validation_result=validation_result,
            file_path=f"workflow_{workflow_id}.py"
        )
        
        return WorkflowV2CodeResponse(
            success=True,
            message="è·å–å·¥ä½œæµä»£ç æˆåŠŸ",
            data=result
        )
        
    except ValueError as e:
        logger.error(f"Workflow v2 code generation validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Get Workflow v2 code failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œæµä»£ç å¤±è´¥: {str(e)}")


@router.post("/workflows-v2/{workflow_id}/code/regenerate", response_model=WorkflowV2CodeResponse, tags=["workflow-v2"])
async def regenerate_workflow_code_v2(
    workflow_id: str,
    request: WorkflowV2CodeGenerationRequest,
    user_id: str = Depends(_get_current_user_id)
):
    """
    é‡æ–°ç”ŸæˆWorkflow v2çš„Pythonä»£ç 
    """
    try:
        logger.info(f"Regenerating Workflow v2 code: {workflow_id}")
        
        # è·å–å·¥ä½œæµé…ç½®
        config = await workflow_v2_manager.get_workflow_config(workflow_id)
        if not config:
            raise HTTPException(status_code=404, detail=f"å·¥ä½œæµ {workflow_id} ä¸å­˜åœ¨")
        
        # é‡æ–°ç”Ÿæˆä»£ç 
        python_code = workflow_v2_manager.code_generator.generate_workflow_code(config)
        
        # éªŒè¯ä»£ç 
        validation_result = workflow_v2_manager.code_generator.validate_generated_code(python_code)
        
        # ä¿å­˜æ›´æ–°çš„ä»£ç 
        await workflow_v2_manager._save_workflow_config(config, python_code)
        
        result = WorkflowV2CodeGenerationResult(
            workflow_id=workflow_id,
            generated_code=python_code,
            validation_result=validation_result,
            file_path=f"workflow_{workflow_id}.py"
        )
        
        return WorkflowV2CodeResponse(
            success=True,
            message="é‡æ–°ç”Ÿæˆå·¥ä½œæµä»£ç æˆåŠŸ",
            data=result
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Regenerate Workflow v2 code failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"é‡æ–°ç”Ÿæˆå·¥ä½œæµä»£ç å¤±è´¥: {str(e)}")


# é…ç½®ç›¸å…³æ¥å£
@router.get("/workflows-v2/models/available", response_model=BaseDataResponse, tags=["workflow-v2"])
async def get_available_models_v2():
    """
    è·å–å¯ç”¨çš„ç¡…åŸºæµåŠ¨æ¨¡å‹åˆ—è¡¨
    """
    try:
        from ..config.siliconflow_config import siliconflow_config
        
        models = []
        for model_config in siliconflow_config.available_models:
            models.append({
                "model_id": model_config.model_id,
                "model_name": model_config.model_name,
                "model_type": model_config.model_type.value,
                "description": model_config.description,
                "max_tokens": model_config.max_tokens,
                "context_window": model_config.context_window,
                "supports_streaming": model_config.supports_streaming,
                "supports_function_calling": model_config.supports_function_calling,
                "pricing": model_config.pricing
            })
        
        return BaseDataResponse(
            success=True,
            message="è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨æˆåŠŸ",
            data={
                "models": models,
                "default_chat_model": siliconflow_config.default_chat_model,
                "default_embedding_model": siliconflow_config.default_embedding_model,
                "default_rerank_model": siliconflow_config.default_rerank_model
            }
        )
        
    except Exception as e:
        logger.error(f"Get available models failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å¯ç”¨æ¨¡å‹å¤±è´¥: {str(e)}")


@router.get("/workflows-v2/tools/available", response_model=BaseDataResponse, tags=["workflow-v2"])
async def get_available_tools_v2():
    """
    è·å–å¯ç”¨çš„å·¥å…·åˆ—è¡¨
    """
    try:
        tools = [
            {
                "id": "reasoning",
                "name": "æ¨ç†å·¥å…·",
                "description": "æä¾›é€»è¾‘æ¨ç†å’Œåˆ†æèƒ½åŠ›",
                "type": "builtin"
            },
            {
                "id": "search",
                "name": "æœç´¢å·¥å…·",
                "description": "æä¾›ä¿¡æ¯æ£€ç´¢å’Œæœç´¢èƒ½åŠ›",
                "type": "builtin"
            },
            {
                "id": "calculator",
                "name": "è®¡ç®—å™¨å·¥å…·",
                "description": "æä¾›æ•°å­¦è®¡ç®—èƒ½åŠ›",
                "type": "builtin"
            },
            {
                "id": "file",
                "name": "æ–‡ä»¶å·¥å…·",
                "description": "æä¾›æ–‡ä»¶è¯»å†™å’Œç®¡ç†èƒ½åŠ›",
                "type": "builtin"
            },
            {
                "id": "web_search",
                "name": "ç½‘ç»œæœç´¢å·¥å…·",
                "description": "æä¾›ç½‘ç»œä¿¡æ¯æœç´¢èƒ½åŠ›",
                "type": "builtin"
            }
        ]
        
        return BaseDataResponse(
            success=True,
            message="è·å–å¯ç”¨å·¥å…·åˆ—è¡¨æˆåŠŸ",
            data={"tools": tools}
        )
        
    except Exception as e:
        logger.error(f"Get available tools failed: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å¯ç”¨å·¥å…·å¤±è´¥: {str(e)}")