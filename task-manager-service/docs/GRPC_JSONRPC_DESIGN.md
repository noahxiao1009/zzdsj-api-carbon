# gRPC & JSON-RPC é€šä¿¡åè®®è®¾è®¡

## ğŸ¯ åè®®é€‰æ‹©ç­–ç•¥

### é€šä¿¡åœºæ™¯åˆ†æ

```mermaid
graph TB
    A[å‰ç«¯ç”¨æˆ·] --> B[Gateway Service]
    B --> C[Knowledge Service]
    B --> D[Search Service]
    B --> E[Config Service]
    
    C --> F[Task Manager]
    F --> G[Document Service]
    F --> H[Vector Service]  
    F --> I[Text Service]
    F --> J[Index Service]
    
    subgraph "HTTP REST API"
        A --> B
        B --> C
        B --> D
    end
    
    subgraph "gRPC (High Performance)"
        F --> G
        F --> H
        F --> I
        F --> J
    end
    
    subgraph "JSON-RPC (Simple)"
        C --> E
        D --> E
    end
```

### åè®®é€‚ç”¨åœºæ™¯

| é€šä¿¡ç±»å‹ | åè®®é€‰æ‹© | é€‚ç”¨åœºæ™¯ | æ€§èƒ½è¦æ±‚ |
|---------|---------|---------|---------|
| å‰ç«¯äº¤äº’ | HTTP REST | ç”¨æˆ·ç•Œé¢æ“ä½œ | ä¸­ç­‰ |
| ä»»åŠ¡è°ƒåº¦ | gRPC | é«˜é¢‘å¼‚æ­¥ä»»åŠ¡ | æé«˜ |
| é…ç½®ç®¡ç† | JSON-RPC | ä½é¢‘é…ç½®æŸ¥è¯¢ | ä½ |
| æœç´¢æŸ¥è¯¢ | HTTP REST | å®æ—¶æœç´¢è¯·æ±‚ | é«˜ |

## ğŸš€ gRPC åè®®è®¾è®¡

### 1. æ ¸å¿ƒæœåŠ¡å®šä¹‰

#### ä»»åŠ¡ç®¡ç†æœåŠ¡ (Task Manager Service)

```protobuf
// protos/task_manager.proto
syntax = "proto3";

package task_manager.v1;
option go_package = "task-manager-service/pkg/proto/task_manager";

import "google/protobuf/timestamp.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/empty.proto";

// ä»»åŠ¡ç®¡ç†æœåŠ¡
service TaskManagerService {
    // æäº¤å•ä¸ªä»»åŠ¡
    rpc SubmitTask(TaskSubmitRequest) returns (TaskSubmitResponse);
    
    // æ‰¹é‡æäº¤ä»»åŠ¡
    rpc SubmitBatchTasks(BatchTaskSubmitRequest) returns (BatchTaskSubmitResponse);
    
    // æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    rpc GetTaskStatus(TaskStatusRequest) returns (TaskStatusResponse);
    
    // æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨
    rpc ListTasks(TaskListRequest) returns (TaskListResponse);
    
    // å–æ¶ˆä»»åŠ¡
    rpc CancelTask(TaskCancelRequest) returns (TaskCancelResponse);
    
    // é‡è¯•ä»»åŠ¡
    rpc RetryTask(TaskRetryRequest) returns (TaskRetryResponse);
    
    // ç›‘å¬ä»»åŠ¡çŠ¶æ€å˜åŒ– (Server Streaming)
    rpc WatchTaskStatus(TaskWatchRequest) returns (stream TaskStatusUpdate);
    
    // å®æ—¶ä»»åŠ¡ç»Ÿè®¡ (Server Streaming)
    rpc StreamTaskStats(google.protobuf.Empty) returns (stream TaskStatsUpdate);
    
    // åŒå‘ä»»åŠ¡å¤„ç†æµ (Bidirectional Streaming)
    rpc ProcessTaskStream(stream TaskProcessRequest) returns (stream TaskProcessResponse);
}

// ä»»åŠ¡ç±»å‹æšä¸¾
enum TaskType {
    TASK_TYPE_UNSPECIFIED = 0;
    TASK_TYPE_DOCUMENT_PROCESSING = 1;
    TASK_TYPE_TEXT_PROCESSING = 2;
    TASK_TYPE_VECTOR_PROCESSING = 3;
    TASK_TYPE_INDEX_MANAGEMENT = 4;
    TASK_TYPE_BATCH_PROCESSING = 5;
    TASK_TYPE_HEALTH_CHECK = 6;
}

// ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾
enum TaskPriority {
    TASK_PRIORITY_UNSPECIFIED = 0;
    TASK_PRIORITY_LOW = 1;
    TASK_PRIORITY_NORMAL = 2;
    TASK_PRIORITY_HIGH = 3;
    TASK_PRIORITY_CRITICAL = 4;
}

// ä»»åŠ¡çŠ¶æ€æšä¸¾
enum TaskStatus {
    TASK_STATUS_UNSPECIFIED = 0;
    TASK_STATUS_QUEUED = 1;
    TASK_STATUS_PROCESSING = 2;
    TASK_STATUS_COMPLETED = 3;
    TASK_STATUS_FAILED = 4;
    TASK_STATUS_CANCELED = 5;
    TASK_STATUS_RETRYING = 6;
}

// ä»»åŠ¡æäº¤è¯·æ±‚
message TaskSubmitRequest {
    TaskType task_type = 1;
    string service_name = 2;
    string knowledge_base_id = 3;
    TaskPriority priority = 4;
    map<string, string> payload = 5;
    int32 max_retries = 6;
    google.protobuf.Duration timeout = 7;
    google.protobuf.Timestamp schedule_for = 8;
    map<string, string> metadata = 9;
}

// ä»»åŠ¡æäº¤å“åº”
message TaskSubmitResponse {
    string task_id = 1;
    TaskStatus status = 2;
    string message = 3;
    google.protobuf.Timestamp created_at = 4;
    google.protobuf.Timestamp estimated_completion = 5;
    int32 queue_position = 6;
}

// æ‰¹é‡ä»»åŠ¡æäº¤è¯·æ±‚
message BatchTaskSubmitRequest {
    repeated TaskSubmitRequest tasks = 1;
    bool fail_on_first_error = 2;
}

// æ‰¹é‡ä»»åŠ¡æäº¤å“åº”
message BatchTaskSubmitResponse {
    repeated TaskSubmitResponse tasks = 1;
    int32 total_submitted = 2;
    int32 total_failed = 3;
}

// ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢è¯·æ±‚
message TaskStatusRequest {
    string task_id = 1;
    bool include_result = 2;
    bool include_logs = 3;
}

// ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å“åº”
message TaskStatusResponse {
    string task_id = 1;
    TaskType task_type = 2;
    TaskStatus status = 3;
    TaskPriority priority = 4;
    string knowledge_base_id = 5;
    int32 progress = 6;
    int32 retry_count = 7;
    int32 max_retries = 8;
    string error_message = 9;
    string worker_id = 10;
    google.protobuf.Timestamp created_at = 11;
    google.protobuf.Timestamp updated_at = 12;
    google.protobuf.Timestamp started_at = 13;
    google.protobuf.Timestamp completed_at = 14;
    map<string, string> payload = 15;
    map<string, string> result = 16;
    repeated string logs = 17;
}

// ä»»åŠ¡ç›‘å¬è¯·æ±‚
message TaskWatchRequest {
    oneof filter {
        string task_id = 1;
        string knowledge_base_id = 2;
        TaskType task_type = 3;
        TaskStatus status = 4;
    }
}

// ä»»åŠ¡çŠ¶æ€æ›´æ–°
message TaskStatusUpdate {
    string task_id = 1;
    TaskStatus old_status = 2;
    TaskStatus new_status = 3;
    int32 progress = 4;
    string message = 5;
    google.protobuf.Timestamp timestamp = 6;
}
```

#### æ–‡æ¡£å¤„ç†æœåŠ¡ (Document Processing Service)

```protobuf
// protos/document_service.proto
syntax = "proto3";

package document_processing.v1;
option go_package = "task-manager-service/pkg/proto/document_processing";

import "google/protobuf/timestamp.proto";

// æ–‡æ¡£å¤„ç†æœåŠ¡
service DocumentProcessingService {
    // å¤„ç†å•ä¸ªæ–‡æ¡£
    rpc ProcessDocument(DocumentProcessRequest) returns (DocumentProcessResponse);
    
    // æ‰¹é‡å¤„ç†æ–‡æ¡£
    rpc BatchProcessDocuments(BatchDocumentRequest) returns (BatchDocumentResponse);
    
    // å¤„ç†URLæ–‡æ¡£
    rpc ProcessURL(URLProcessRequest) returns (URLProcessResponse);
    
    // è·å–å¤„ç†çŠ¶æ€
    rpc GetProcessingStatus(ProcessingStatusRequest) returns (ProcessingStatusResponse);
    
    // æµå¼æ–‡æ¡£å¤„ç† (Client Streaming)
    rpc StreamProcessDocuments(stream DocumentProcessRequest) returns (BatchDocumentResponse);
}

// æ–‡æ¡£ç±»å‹æšä¸¾
enum DocumentType {
    DOCUMENT_TYPE_UNSPECIFIED = 0;
    DOCUMENT_TYPE_PDF = 1;
    DOCUMENT_TYPE_WORD = 2;
    DOCUMENT_TYPE_TEXT = 3;
    DOCUMENT_TYPE_MARKDOWN = 4;
    DOCUMENT_TYPE_HTML = 5;
    DOCUMENT_TYPE_EXCEL = 6;
    DOCUMENT_TYPE_POWERPOINT = 7;
}

// æ–‡æ¡£å¤„ç†è¯·æ±‚
message DocumentProcessRequest {
    string task_id = 1;
    string knowledge_base_id = 2;
    string file_path = 3;
    string filename = 4;
    DocumentType document_type = 5;
    string title = 6;
    map<string, string> metadata = 7;
    ProcessingConfig config = 8;
}

// å¤„ç†é…ç½®
message ProcessingConfig {
    bool extract_tables = 1;
    bool extract_images = 2;
    bool preserve_formatting = 3;
    string language = 4;
    int32 max_file_size_mb = 5;
}

// æ–‡æ¡£å¤„ç†å“åº”
message DocumentProcessResponse {
    string task_id = 1;
    bool success = 2;
    string message = 3;
    ExtractedContent content = 4;
    ProcessingStats stats = 5;
    google.protobuf.Timestamp processed_at = 6;
}

// æå–çš„å†…å®¹
message ExtractedContent {
    string text = 1;
    repeated TableData tables = 2;
    repeated ImageData images = 3;
    map<string, string> metadata = 4;
    StructureInfo structure = 5;
}

// è¡¨æ ¼æ•°æ®
message TableData {
    repeated repeated string rows = 1;
    repeated string headers = 2;
    string caption = 3;
    int32 page_number = 4;
}

// å›¾åƒæ•°æ®
message ImageData {
    string image_path = 1;
    string caption = 2;
    int32 width = 3;
    int32 height = 4;
    int32 page_number = 5;
}

// ç»“æ„ä¿¡æ¯
message StructureInfo {
    repeated Heading headings = 1;
    repeated Paragraph paragraphs = 2;
    int32 total_pages = 3;
    int32 total_words = 4;
}

// æ ‡é¢˜ä¿¡æ¯
message Heading {
    string text = 1;
    int32 level = 2;
    int32 page_number = 3;
}

// æ®µè½ä¿¡æ¯
message Paragraph {
    string text = 1;
    int32 page_number = 2;
    string style = 3;
}

// å¤„ç†ç»Ÿè®¡
message ProcessingStats {
    google.protobuf.Duration processing_time = 1;
    int64 file_size_bytes = 2;
    int32 pages_processed = 3;
    int32 tables_extracted = 4;
    int32 images_extracted = 5;
    int32 words_extracted = 6;
}
```

#### å‘é‡å¤„ç†æœåŠ¡ (Vector Processing Service)

```protobuf
// protos/vector_service.proto
syntax = "proto3";

package vector_processing.v1;
option go_package = "task-manager-service/pkg/proto/vector_processing";

import "google/protobuf/timestamp.proto";

// å‘é‡å¤„ç†æœåŠ¡
service VectorProcessingService {
    // ç”Ÿæˆå‘é‡
    rpc GenerateEmbeddings(EmbeddingRequest) returns (EmbeddingResponse);
    
    // æ‰¹é‡ç”Ÿæˆå‘é‡
    rpc BatchGenerateEmbeddings(BatchEmbeddingRequest) returns (BatchEmbeddingResponse);
    
    // å­˜å‚¨å‘é‡
    rpc StoreVectors(VectorStorageRequest) returns (VectorStorageResponse);
    
    // å‘é‡ç›¸ä¼¼åº¦æœç´¢
    rpc SearchSimilarVectors(VectorSearchRequest) returns (VectorSearchResponse);
    
    // æµå¼å‘é‡å¤„ç† (Bidirectional Streaming)
    rpc StreamVectorProcessing(stream VectorProcessRequest) returns (stream VectorProcessResponse);
}

// æ¨¡å‹ç±»å‹æšä¸¾
enum EmbeddingModel {
    EMBEDDING_MODEL_UNSPECIFIED = 0;
    EMBEDDING_MODEL_TEXT_EMBEDDING_ADA_002 = 1;
    EMBEDDING_MODEL_TEXT_EMBEDDING_3_SMALL = 2;
    EMBEDDING_MODEL_TEXT_EMBEDDING_3_LARGE = 3;
    EMBEDDING_MODEL_BGE_LARGE_ZH = 4;
    EMBEDDING_MODEL_SILICONFLOW_BGE = 5;
}

// å‘é‡ç”Ÿæˆè¯·æ±‚
message EmbeddingRequest {
    string task_id = 1;
    repeated string texts = 2;
    EmbeddingModel model = 3;
    int32 max_tokens = 4;
    map<string, string> model_params = 5;
}

// å‘é‡ç”Ÿæˆå“åº”
message EmbeddingResponse {
    string task_id = 1;
    bool success = 2;
    string message = 3;
    repeated Vector vectors = 4;
    EmbeddingStats stats = 5;
    google.protobuf.Timestamp generated_at = 6;
}

// å‘é‡æ•°æ®
message Vector {
    string id = 1;
    repeated float values = 2;
    string text = 3;
    map<string, string> metadata = 4;
}

// å‘é‡ç»Ÿè®¡
message EmbeddingStats {
    int32 total_texts = 1;
    int32 successful_embeddings = 2;
    int32 failed_embeddings = 3;
    google.protobuf.Duration processing_time = 4;
    int32 total_tokens = 5;
    float average_tokens_per_text = 6;
}

// å‘é‡å­˜å‚¨è¯·æ±‚
message VectorStorageRequest {
    string task_id = 1;
    string knowledge_base_id = 2;
    string collection_name = 3;
    repeated Vector vectors = 4;
    StorageConfig config = 5;
}

// å­˜å‚¨é…ç½®
message StorageConfig {
    string index_type = 1;
    int32 dimension = 2;
    string metric_type = 3;
    map<string, string> index_params = 4;
    bool upsert_mode = 5;
}

// å‘é‡å­˜å‚¨å“åº”
message VectorStorageResponse {
    string task_id = 1;
    bool success = 2;
    string message = 3;
    int32 stored_count = 4;
    repeated string stored_ids = 5;
    google.protobuf.Timestamp stored_at = 6;
}
```

### 2. gRPC å®¢æˆ·ç«¯å®ç°

#### Go å®¢æˆ·ç«¯å®ç°

```go
// pkg/grpc/client/task_client.go
package client

import (
    "context"
    "fmt"
    "time"

    "google.golang.org/grpc"
    "google.golang.org/grpc/credentials/insecure"
    
    pb "task-manager-service/pkg/proto/task_manager"
)

type TaskManagerClient struct {
    conn   *grpc.ClientConn
    client pb.TaskManagerServiceClient
}

func NewTaskManagerClient(address string) (*TaskManagerClient, error) {
    conn, err := grpc.Dial(address, 
        grpc.WithTransportCredentials(insecure.NewCredentials()),
        grpc.WithTimeout(10*time.Second),
    )
    if err != nil {
        return nil, fmt.Errorf("failed to connect to task manager: %w", err)
    }

    return &TaskManagerClient{
        conn:   conn,
        client: pb.NewTaskManagerServiceClient(conn),
    }, nil
}

func (c *TaskManagerClient) SubmitTask(ctx context.Context, req *pb.TaskSubmitRequest) (*pb.TaskSubmitResponse, error) {
    return c.client.SubmitTask(ctx, req)
}

func (c *TaskManagerClient) WatchTaskStatus(ctx context.Context, taskID string) (<-chan *pb.TaskStatusUpdate, error) {
    stream, err := c.client.WatchTaskStatus(ctx, &pb.TaskWatchRequest{
        Filter: &pb.TaskWatchRequest_TaskId{TaskId: taskID},
    })
    if err != nil {
        return nil, err
    }

    updates := make(chan *pb.TaskStatusUpdate)
    
    go func() {
        defer close(updates)
        for {
            update, err := stream.Recv()
            if err != nil {
                return
            }
            select {
            case updates <- update:
            case <-ctx.Done():
                return
            }
        }
    }()

    return updates, nil
}

func (c *TaskManagerClient) Close() error {
    return c.conn.Close()
}
```

#### Python å¼‚æ­¥å®¢æˆ·ç«¯å®ç°

```python
# app/grpc/clients/task_client.py
import asyncio
import grpc
from typing import AsyncIterator, Optional, Dict, Any

from ..protos import task_manager_pb2
from ..protos import task_manager_pb2_grpc

class AsyncTaskManagerClient:
    """å¼‚æ­¥ä»»åŠ¡ç®¡ç†å™¨å®¢æˆ·ç«¯"""
    
    def __init__(self, address: str = "localhost:8084"):
        self.address = address
        self.channel: Optional[grpc.aio.Channel] = None
        self.stub: Optional[task_manager_pb2_grpc.TaskManagerServiceStub] = None
    
    async def connect(self):
        """å»ºç«‹è¿æ¥"""
        self.channel = grpc.aio.insecure_channel(self.address)
        self.stub = task_manager_pb2_grpc.TaskManagerServiceStub(self.channel)
        
        # æµ‹è¯•è¿æ¥
        try:
            await self.stub.GetTaskStatus(
                task_manager_pb2.TaskStatusRequest(task_id="test"),
                timeout=5
            )
        except grpc.RpcError:
            pass  # è¿æ¥æˆåŠŸï¼Œä»»åŠ¡ä¸å­˜åœ¨æ˜¯æ­£å¸¸çš„
    
    async def submit_task(
        self, 
        task_type: str,
        kb_id: str,
        payload: Dict[str, Any],
        priority: str = "normal",
        max_retries: int = 3
    ) -> task_manager_pb2.TaskSubmitResponse:
        """æäº¤ä»»åŠ¡"""
        
        # è½¬æ¢ä»»åŠ¡ç±»å‹
        task_type_enum = self._convert_task_type(task_type)
        priority_enum = self._convert_priority(priority)
        
        request = task_manager_pb2.TaskSubmitRequest(
            task_type=task_type_enum,
            service_name="knowledge-service",
            knowledge_base_id=kb_id,
            priority=priority_enum,
            payload=payload,
            max_retries=max_retries
        )
        
        return await self.stub.SubmitTask(request)
    
    async def get_task_status(self, task_id: str) -> task_manager_pb2.TaskStatusResponse:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        request = task_manager_pb2.TaskStatusRequest(
            task_id=task_id,
            include_result=True,
            include_logs=True
        )
        
        return await self.stub.GetTaskStatus(request)
    
    async def watch_task_status(self, task_id: str) -> AsyncIterator[task_manager_pb2.TaskStatusUpdate]:
        """ç›‘å¬ä»»åŠ¡çŠ¶æ€å˜åŒ–"""
        request = task_manager_pb2.TaskWatchRequest(task_id=task_id)
        
        async for update in self.stub.WatchTaskStatus(request):
            yield update
    
    async def batch_submit_tasks(
        self, 
        tasks: list
    ) -> task_manager_pb2.BatchTaskSubmitResponse:
        """æ‰¹é‡æäº¤ä»»åŠ¡"""
        
        task_requests = []
        for task in tasks:
            req = task_manager_pb2.TaskSubmitRequest(
                task_type=self._convert_task_type(task["task_type"]),
                service_name="knowledge-service",
                knowledge_base_id=task["kb_id"],
                priority=self._convert_priority(task.get("priority", "normal")),
                payload=task["payload"],
                max_retries=task.get("max_retries", 3)
            )
            task_requests.append(req)
        
        request = task_manager_pb2.BatchTaskSubmitRequest(
            tasks=task_requests,
            fail_on_first_error=False
        )
        
        return await self.stub.SubmitBatchTasks(request)
    
    def _convert_task_type(self, task_type: str) -> int:
        """è½¬æ¢ä»»åŠ¡ç±»å‹"""
        mapping = {
            "document_processing": task_manager_pb2.TASK_TYPE_DOCUMENT_PROCESSING,
            "text_processing": task_manager_pb2.TASK_TYPE_TEXT_PROCESSING,
            "vector_processing": task_manager_pb2.TASK_TYPE_VECTOR_PROCESSING,
            "index_management": task_manager_pb2.TASK_TYPE_INDEX_MANAGEMENT,
            "batch_processing": task_manager_pb2.TASK_TYPE_BATCH_PROCESSING,
        }
        return mapping.get(task_type, task_manager_pb2.TASK_TYPE_UNSPECIFIED)
    
    def _convert_priority(self, priority: str) -> int:
        """è½¬æ¢ä¼˜å…ˆçº§"""
        mapping = {
            "low": task_manager_pb2.TASK_PRIORITY_LOW,
            "normal": task_manager_pb2.TASK_PRIORITY_NORMAL,
            "high": task_manager_pb2.TASK_PRIORITY_HIGH,
            "critical": task_manager_pb2.TASK_PRIORITY_CRITICAL,
        }
        return mapping.get(priority, task_manager_pb2.TASK_PRIORITY_NORMAL)
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.channel:
            await self.channel.close()

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    client = AsyncTaskManagerClient("localhost:8084")
    await client.connect()
    
    try:
        # æäº¤æ–‡æ¡£å¤„ç†ä»»åŠ¡
        response = await client.submit_task(
            task_type="document_processing",
            kb_id="kb_123",
            payload={
                "file_path": "/tmp/uploads/document.pdf",
                "filename": "document.pdf",
                "chunk_size": "1000",
                "chunk_overlap": "200"
            },
            priority="high"
        )
        
        print(f"ä»»åŠ¡å·²æäº¤: {response.task_id}")
        
        # ç›‘å¬ä»»åŠ¡çŠ¶æ€å˜åŒ–
        async for update in client.watch_task_status(response.task_id):
            print(f"ä»»åŠ¡çŠ¶æ€æ›´æ–°: {update.new_status}, è¿›åº¦: {update.progress}%")
            
            if update.new_status in ["TASK_STATUS_COMPLETED", "TASK_STATUS_FAILED"]:
                break
                
    finally:
        await client.close()
```

## ğŸ”Œ JSON-RPC åè®®è®¾è®¡

### 1. é…ç½®ç®¡ç†æœåŠ¡åè®®

```python
# app/jsonrpc/config_service.py
from typing import Dict, Any, Optional, List
import json

class ConfigServiceRPC:
    """é…ç½®ç®¡ç†æœåŠ¡ JSON-RPC æ¥å£"""
    
    # åˆ‡åˆ†ç­–ç•¥ç®¡ç†
    async def get_chunking_strategy(self, strategy_id: str) -> Dict[str, Any]:
        """è·å–åˆ‡åˆ†ç­–ç•¥é…ç½®"""
        return {
            "jsonrpc": "2.0",
            "method": "get_chunking_strategy",
            "params": {"strategy_id": strategy_id},
            "id": self._generate_id()
        }
    
    async def list_chunking_strategies(self, kb_id: Optional[str] = None) -> Dict[str, Any]:
        """åˆ—å‡ºæ‰€æœ‰åˆ‡åˆ†ç­–ç•¥"""
        params = {}
        if kb_id:
            params["kb_id"] = kb_id
            
        return {
            "jsonrpc": "2.0",
            "method": "list_chunking_strategies",
            "params": params,
            "id": self._generate_id()
        }
    
    async def create_chunking_strategy(
        self, 
        name: str, 
        strategy_type: str,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åˆ›å»ºåˆ‡åˆ†ç­–ç•¥"""
        return {
            "jsonrpc": "2.0",
            "method": "create_chunking_strategy",
            "params": {
                "name": name,
                "strategy_type": strategy_type,
                "config": config
            },
            "id": self._generate_id()
        }
    
    async def update_chunking_strategy(
        self, 
        strategy_id: str, 
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ›´æ–°åˆ‡åˆ†ç­–ç•¥"""
        return {
            "jsonrpc": "2.0",
            "method": "update_chunking_strategy",
            "params": {
                "strategy_id": strategy_id,
                "config": config
            },
            "id": self._generate_id()
        }
    
    # æ¨¡å‹é…ç½®ç®¡ç†
    async def get_embedding_models(self) -> Dict[str, Any]:
        """è·å–å¯ç”¨çš„åµŒå…¥æ¨¡å‹åˆ—è¡¨"""
        return {
            "jsonrpc": "2.0",
            "method": "get_embedding_models",
            "params": {},
            "id": self._generate_id()
        }
    
    async def get_model_config(self, model_name: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹é…ç½®"""
        return {
            "jsonrpc": "2.0",
            "method": "get_model_config",
            "params": {"model_name": model_name},
            "id": self._generate_id()
        }
    
    async def update_model_config(
        self, 
        model_name: str, 
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ›´æ–°æ¨¡å‹é…ç½®"""
        return {
            "jsonrpc": "2.0",
            "method": "update_model_config",
            "params": {
                "model_name": model_name,
                "config": config
            },
            "id": self._generate_id()
        }
    
    # ç³»ç»Ÿé…ç½®ç®¡ç†
    async def get_system_config(self, config_key: str) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿé…ç½®"""
        return {
            "jsonrpc": "2.0",
            "method": "get_system_config",
            "params": {"config_key": config_key},
            "id": self._generate_id()
        }
    
    async def update_system_config(
        self, 
        config_key: str, 
        config_value: Any
    ) -> Dict[str, Any]:
        """æ›´æ–°ç³»ç»Ÿé…ç½®"""
        return {
            "jsonrpc": "2.0",
            "method": "update_system_config",
            "params": {
                "config_key": config_key,
                "config_value": config_value
            },
            "id": self._generate_id()
        }
    
    # çŸ¥è¯†åº“é…ç½®ç®¡ç†
    async def get_knowledge_base_config(self, kb_id: str) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“é…ç½®"""
        return {
            "jsonrpc": "2.0",
            "method": "get_knowledge_base_config",
            "params": {"kb_id": kb_id},
            "id": self._generate_id()
        }
    
    async def update_knowledge_base_config(
        self, 
        kb_id: str, 
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ›´æ–°çŸ¥è¯†åº“é…ç½®"""
        return {
            "jsonrpc": "2.0",
            "method": "update_knowledge_base_config",
            "params": {
                "kb_id": kb_id,
                "config": config
            },
            "id": self._generate_id()
        }
    
    def _generate_id(self) -> str:
        """ç”Ÿæˆè¯·æ±‚ID"""
        import uuid
        return str(uuid.uuid4())

# JSON-RPC å“åº”æ ¼å¼å®šä¹‰
class ConfigServiceResponse:
    """é…ç½®æœåŠ¡å“åº”æ ¼å¼"""
    
    @staticmethod
    def success_response(request_id: str, result: Any) -> Dict[str, Any]:
        """æˆåŠŸå“åº”"""
        return {
            "jsonrpc": "2.0",
            "result": result,
            "id": request_id
        }
    
    @staticmethod
    def error_response(request_id: str, error_code: int, error_message: str) -> Dict[str, Any]:
        """é”™è¯¯å“åº”"""
        return {
            "jsonrpc": "2.0",
            "error": {
                "code": error_code,
                "message": error_message
            },
            "id": request_id
        }

# é”™è¯¯ç å®šä¹‰
class ConfigServiceErrors:
    """é…ç½®æœåŠ¡é”™è¯¯ç """
    
    PARSE_ERROR = -32700      # è§£æé”™è¯¯
    INVALID_REQUEST = -32600  # æ— æ•ˆè¯·æ±‚
    METHOD_NOT_FOUND = -32601 # æ–¹æ³•ä¸å­˜åœ¨
    INVALID_PARAMS = -32602   # æ— æ•ˆå‚æ•°
    INTERNAL_ERROR = -32603   # å†…éƒ¨é”™è¯¯
    
    # ä¸šåŠ¡é”™è¯¯ç  (è‡ªå®šä¹‰)
    STRATEGY_NOT_FOUND = 1001      # ç­–ç•¥ä¸å­˜åœ¨
    MODEL_NOT_FOUND = 1002         # æ¨¡å‹ä¸å­˜åœ¨
    CONFIG_NOT_FOUND = 1003        # é…ç½®ä¸å­˜åœ¨
    PERMISSION_DENIED = 1004       # æƒé™æ‹’ç»
    CONFIG_VALIDATION_ERROR = 1005 # é…ç½®éªŒè¯é”™è¯¯
```

### 2. æœç´¢æŸ¥è¯¢æœåŠ¡åè®®

```python
# app/jsonrpc/search_service.py
class SearchServiceRPC:
    """æœç´¢æŸ¥è¯¢æœåŠ¡ JSON-RPC æ¥å£"""
    
    async def vector_search(
        self, 
        kb_id: str, 
        query_text: str, 
        top_k: int = 10,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """å‘é‡ç›¸ä¼¼åº¦æœç´¢"""
        params = {
            "kb_id": kb_id,
            "query_text": query_text,
            "top_k": top_k
        }
        if filters:
            params["filters"] = filters
            
        return {
            "jsonrpc": "2.0",
            "method": "vector_search",
            "params": params,
            "id": self._generate_id()
        }
    
    async def full_text_search(
        self, 
        kb_id: str, 
        query_text: str,
        page: int = 1,
        page_size: int = 20,
        highlight: bool = True
    ) -> Dict[str, Any]:
        """å…¨æ–‡æ£€ç´¢æœç´¢"""
        return {
            "jsonrpc": "2.0",
            "method": "full_text_search",
            "params": {
                "kb_id": kb_id,
                "query_text": query_text,
                "page": page,
                "page_size": page_size,
                "highlight": highlight
            },
            "id": self._generate_id()
        }
    
    async def hybrid_search(
        self, 
        kb_id: str, 
        query_text: str,
        vector_weight: float = 0.7,
        text_weight: float = 0.3,
        top_k: int = 10
    ) -> Dict[str, Any]:
        """æ··åˆæ£€ç´¢æœç´¢"""
        return {
            "jsonrpc": "2.0",
            "method": "hybrid_search",
            "params": {
                "kb_id": kb_id,
                "query_text": query_text,
                "vector_weight": vector_weight,
                "text_weight": text_weight,
                "top_k": top_k
            },
            "id": self._generate_id()
        }
    
    async def semantic_search(
        self, 
        kb_id: str, 
        query_text: str,
        semantic_threshold: float = 0.75,
        top_k: int = 10
    ) -> Dict[str, Any]:
        """è¯­ä¹‰æœç´¢"""
        return {
            "jsonrpc": "2.0",
            "method": "semantic_search",
            "params": {
                "kb_id": kb_id,
                "query_text": query_text,
                "semantic_threshold": semantic_threshold,
                "top_k": top_k
            },
            "id": self._generate_id()
        }
    
    async def search_suggestions(
        self, 
        kb_id: str, 
        partial_query: str,
        max_suggestions: int = 5
    ) -> Dict[str, Any]:
        """æœç´¢å»ºè®®"""
        return {
            "jsonrpc": "2.0",
            "method": "search_suggestions",
            "params": {
                "kb_id": kb_id,
                "partial_query": partial_query,
                "max_suggestions": max_suggestions
            },
            "id": self._generate_id()
        }
```

### 3. JSON-RPC å®¢æˆ·ç«¯å®ç°

```python
# app/jsonrpc/client.py
import httpx
import json
from typing import Dict, Any, Optional

class JSONRPCClient:
    """JSON-RPC å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, timeout: int = 30):
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
    
    async def call(
        self, 
        method: str, 
        params: Optional[Dict[str, Any]] = None,
        request_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """è°ƒç”¨ JSON-RPC æ–¹æ³•"""
        
        if request_id is None:
            import uuid
            request_id = str(uuid.uuid4())
        
        payload = {
            "jsonrpc": "2.0",
            "method": method,
            "params": params or {},
            "id": request_id
        }
        
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.base_url}/jsonrpc",
                json=payload,
                headers={"Content-Type": "application/json"}
            )
            
            response.raise_for_status()
            result = response.json()
            
            if "error" in result:
                raise JSONRPCError(
                    result["error"]["code"],
                    result["error"]["message"]
                )
            
            return result["result"]
    
    async def batch_call(
        self, 
        calls: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """æ‰¹é‡è°ƒç”¨ JSON-RPC æ–¹æ³•"""
        
        payloads = []
        for call in calls:
            payload = {
                "jsonrpc": "2.0",
                "method": call["method"],
                "params": call.get("params", {}),
                "id": call.get("id", str(uuid.uuid4()))
            }
            payloads.append(payload)
        
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.base_url}/jsonrpc",
                json=payloads,
                headers={"Content-Type": "application/json"}
            )
            
            response.raise_for_status()
            results = response.json()
            
            return results

class JSONRPCError(Exception):
    """JSON-RPC é”™è¯¯"""
    
    def __init__(self, code: int, message: str):
        self.code = code
        self.message = message
        super().__init__(f"JSON-RPC Error {code}: {message}")

# ä½¿ç”¨ç¤ºä¾‹
async def example_config_usage():
    """é…ç½®æœåŠ¡ä½¿ç”¨ç¤ºä¾‹"""
    client = JSONRPCClient("http://localhost:8096")
    
    try:
        # è·å–åˆ‡åˆ†ç­–ç•¥
        strategy = await client.call(
            "get_chunking_strategy",
            {"strategy_id": "semantic_chunking_v1"}
        )
        print(f"åˆ‡åˆ†ç­–ç•¥: {strategy}")
        
        # è·å–æ¨¡å‹é…ç½®
        model_config = await client.call(
            "get_model_config", 
            {"model_name": "text-embedding-ada-002"}
        )
        print(f"æ¨¡å‹é…ç½®: {model_config}")
        
    except JSONRPCError as e:
        print(f"RPCé”™è¯¯: {e}")

async def example_search_usage():
    """æœç´¢æœåŠ¡ä½¿ç”¨ç¤ºä¾‹"""
    client = JSONRPCClient("http://localhost:8095")
    
    try:
        # æ··åˆæœç´¢
        results = await client.call(
            "hybrid_search",
            {
                "kb_id": "kb_123",
                "query_text": "æœºå™¨å­¦ä¹ ç®—æ³•",
                "vector_weight": 0.7,
                "text_weight": 0.3,
                "top_k": 10
            }
        )
        print(f"æœç´¢ç»“æœ: {results}")
        
    except JSONRPCError as e:
        print(f"æœç´¢é”™è¯¯: {e}")
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”æµ‹è¯•

### é€šä¿¡åè®®æ€§èƒ½æµ‹è¯•

```python
# tests/performance/protocol_benchmark.py
import asyncio
import time
import httpx
import grpc
from typing import List

async def benchmark_http_rest():
    """HTTP REST API æ€§èƒ½æµ‹è¯•"""
    async with httpx.AsyncClient() as client:
        start_time = time.time()
        
        tasks = []
        for i in range(1000):
            task = client.post("http://localhost:8082/api/v1/tasks", json={
                "task_type": "document_processing",
                "kb_id": f"kb_{i}",
                "payload": {"test": "data"}
            })
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks)
        end_time = time.time()
        
        return {
            "protocol": "HTTP REST",
            "requests": 1000,
            "time": end_time - start_time,
            "rps": 1000 / (end_time - start_time)
        }

async def benchmark_grpc():
    """gRPC æ€§èƒ½æµ‹è¯•"""
    from app.grpc.clients.task_client import AsyncTaskManagerClient
    
    client = AsyncTaskManagerClient()
    await client.connect()
    
    try:
        start_time = time.time()
        
        tasks = []
        for i in range(1000):
            task = client.submit_task(
                task_type="document_processing",
                kb_id=f"kb_{i}",
                payload={"test": "data"}
            )
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks)
        end_time = time.time()
        
        return {
            "protocol": "gRPC",
            "requests": 1000,
            "time": end_time - start_time,
            "rps": 1000 / (end_time - start_time)
        }
    finally:
        await client.close()

async def benchmark_jsonrpc():
    """JSON-RPC æ€§èƒ½æµ‹è¯•"""
    from app.jsonrpc.client import JSONRPCClient
    
    client = JSONRPCClient("http://localhost:8096")
    
    start_time = time.time()
    
    tasks = []
    for i in range(1000):
        task = client.call(
            "get_chunking_strategy",
            {"strategy_id": f"strategy_{i}"}
        )
        tasks.append(task)
    
    try:
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = time.time()
        
        return {
            "protocol": "JSON-RPC",
            "requests": 1000,
            "time": end_time - start_time,
            "rps": 1000 / (end_time - start_time)
        }
    except Exception as e:
        end_time = time.time()
        return {
            "protocol": "JSON-RPC",
            "requests": 1000,
            "time": end_time - start_time,
            "rps": 1000 / (end_time - start_time),
            "error": str(e)
        }

async def run_benchmark():
    """è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print("å¼€å§‹é€šä¿¡åè®®æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
    
    # HTTP REST æµ‹è¯•
    print("æµ‹è¯• HTTP REST...")
    http_result = await benchmark_http_rest()
    
    # gRPC æµ‹è¯•
    print("æµ‹è¯• gRPC...")
    grpc_result = await benchmark_grpc()
    
    # JSON-RPC æµ‹è¯•
    print("æµ‹è¯• JSON-RPC...")
    jsonrpc_result = await benchmark_jsonrpc()
    
    # è¾“å‡ºç»“æœ
    print("\næ€§èƒ½æµ‹è¯•ç»“æœ:")
    print("-" * 60)
    for result in [http_result, grpc_result, jsonrpc_result]:
        print(f"åè®®: {result['protocol']}")
        print(f"è¯·æ±‚æ•°: {result['requests']}")
        print(f"æ€»æ—¶é—´: {result['time']:.2f}ç§’")
        print(f"RPS: {result['rps']:.2f}")
        if 'error' in result:
            print(f"é”™è¯¯: {result['error']}")
        print("-" * 60)

if __name__ == "__main__":
    asyncio.run(run_benchmark())
```

## ğŸ¯ åè®®å®æ–½æ—¶é—´è¡¨

### Week 1-2: gRPC åŸºç¡€å®æ–½
- [ ] å®šä¹‰æ ¸å¿ƒ protobuf æ–‡ä»¶
- [ ] å®ç° Go è¯­è¨€ gRPC æœåŠ¡ç«¯
- [ ] å®ç° Go è¯­è¨€ gRPC å®¢æˆ·ç«¯
- [ ] Python asyncio gRPC å®¢æˆ·ç«¯å®ç°

### Week 2-3: JSON-RPC å®æ–½
- [ ] é…ç½®ç®¡ç†æœåŠ¡ JSON-RPC æ¥å£è®¾è®¡
- [ ] æœç´¢æŸ¥è¯¢æœåŠ¡ JSON-RPC æ¥å£è®¾è®¡
- [ ] JSON-RPC å®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯å®ç°
- [ ] é”™è¯¯å¤„ç†å’Œå¼‚å¸¸ç®¡ç†

### Week 3-4: æ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•
- [ ] åè®®æ€§èƒ½å¯¹æ¯”æµ‹è¯•
- [ ] è¿æ¥æ± å’Œå¤ç”¨ä¼˜åŒ–
- [ ] è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
- [ ] ç›‘æ§å’Œæ—¥å¿—é›†æˆ

é€šè¿‡è¿™å¥—æ··åˆé€šä¿¡åè®®è®¾è®¡ï¼Œæˆ‘ä»¬å°†å®ç°é«˜æ€§èƒ½çš„æœåŠ¡é—´é€šä¿¡ï¼Œä¸ºå¾®æœåŠ¡æ¶æ„æä¾›å¼ºå¤§çš„æŠ€æœ¯æ”¯æ’‘ï¼ğŸš€