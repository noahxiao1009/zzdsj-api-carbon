"""
çŠ¶æ€ç®¡ç†å™¨ - äº‹ä»¶é©±åŠ¨å·¥ä½œæµçš„çŠ¶æ€ç®¡ç†å’ŒæŒä¹…åŒ–
åŸºäºRediså’ŒPostgreSQLçš„åŒå±‚å­˜å‚¨æ¶æ„
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from uuid import UUID
import uuid

import redis.asyncio as redis
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy import select, update, delete

from ..models.workflow import Workflow, WorkflowStage, WorkflowRole, WorkflowExecution
from ..models.task import Task, TaskComment, TaskActivity
from ..models.event import Event, EventHandler, EventSubscription, EventRule
from ..models.board import Board, BoardColumn


logger = logging.getLogger(__name__)


class StateManager:
    """çŠ¶æ€ç®¡ç†å™¨ - è´Ÿè´£æ•°æ®çŠ¶æ€çš„ç®¡ç†å’ŒæŒä¹…åŒ–"""
    
    def __init__(self):
        self.redis = None
        self.db_engine = None
        self.async_session = None
        self._cache_ttl = 3600  # 1å°æ—¶ç¼“å­˜
        self._is_initialized = False
        
    async def initialize(self):
        """åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨"""
        logger.info("ğŸš€ åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨...")
        
        try:
            # åˆå§‹åŒ–Redisè¿æ¥
            await self._init_redis()
            
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            await self._init_database()
            
            self._is_initialized = True
            logger.info("âœ… çŠ¶æ€ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ çŠ¶æ€ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ”„ æ¸…ç†çŠ¶æ€ç®¡ç†å™¨èµ„æº...")
        
        if self.redis:
            await self.redis.close()
        
        if self.db_engine:
            await self.db_engine.dispose()
        
        logger.info("âœ… çŠ¶æ€ç®¡ç†å™¨èµ„æºæ¸…ç†å®Œæˆ")
    
    def is_healthy(self) -> bool:
        """æ£€æŸ¥çŠ¶æ€ç®¡ç†å™¨å¥åº·çŠ¶æ€"""
        return (self._is_initialized and 
                self.redis is not None and 
                self.db_engine is not None)
    
    # ==================== å·¥ä½œæµç®¡ç† ====================
    
    async def save_workflow(self, workflow: Workflow) -> None:
        """ä¿å­˜å·¥ä½œæµ"""
        try:
            async with self.async_session() as session:
                session.add(workflow)
                await session.commit()
                await session.refresh(workflow)
            
            # ç¼“å­˜åˆ°Redis
            await self._cache_workflow(workflow)
            
            logger.info(f"ğŸ’¾ å·¥ä½œæµä¿å­˜æˆåŠŸ: {workflow.id}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def get_workflow(self, workflow_id: str) -> Optional[Workflow]:
        """è·å–å·¥ä½œæµ"""
        try:
            # å…ˆä»ç¼“å­˜è·å–
            cached = await self._get_cached_workflow(workflow_id)
            if cached:
                return cached
            
            # ä»æ•°æ®åº“è·å–
            async with self.async_session() as session:
                result = await session.execute(
                    select(Workflow).where(Workflow.id == UUID(workflow_id))
                )
                workflow = result.scalar_one_or_none()
                
                if workflow:
                    await self._cache_workflow(workflow)
                
                return workflow
                
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥ä½œæµå¤±è´¥: {workflow_id}, é”™è¯¯: {str(e)}")
            return None
    
    async def update_workflow(self, workflow: Workflow) -> None:
        """æ›´æ–°å·¥ä½œæµ"""
        try:
            async with self.async_session() as session:
                await session.merge(workflow)
                await session.commit()
            
            # æ›´æ–°ç¼“å­˜
            await self._cache_workflow(workflow)
            
            logger.info(f"ğŸ”„ å·¥ä½œæµæ›´æ–°æˆåŠŸ: {workflow.id}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ›´æ–°å¤±è´¥: {str(e)}")
            raise
    
    async def delete_workflow(self, workflow_id: str) -> bool:
        """åˆ é™¤å·¥ä½œæµ"""
        try:
            async with self.async_session() as session:
                result = await session.execute(
                    delete(Workflow).where(Workflow.id == UUID(workflow_id))
                )
                await session.commit()
                
                deleted = result.rowcount > 0
                
                if deleted:
                    # ä»ç¼“å­˜ç§»é™¤
                    await self._remove_cached_workflow(workflow_id)
                    logger.info(f"ğŸ—‘ï¸ å·¥ä½œæµåˆ é™¤æˆåŠŸ: {workflow_id}")
                
                return deleted
                
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµåˆ é™¤å¤±è´¥: {workflow_id}, é”™è¯¯: {str(e)}")
            return False
    
    async def list_workflows(self, page: int = 1, limit: int = 10, status: str = None) -> List[Workflow]:
        """åˆ—å‡ºå·¥ä½œæµ"""
        try:
            async with self.async_session() as session:
                query = select(Workflow)
                
                if status:
                    query = query.where(Workflow.status == status)
                
                query = query.offset((page - 1) * limit).limit(limit)
                query = query.order_by(Workflow.created_at.desc())
                
                result = await session.execute(query)
                workflows = result.scalars().all()
                
                return list(workflows)
                
        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºå·¥ä½œæµå¤±è´¥: {str(e)}")
            return []
    
    # ==================== å·¥ä½œæµé˜¶æ®µç®¡ç† ====================
    
    async def save_workflow_stage(self, stage: WorkflowStage) -> None:
        """ä¿å­˜å·¥ä½œæµé˜¶æ®µ"""
        try:
            async with self.async_session() as session:
                session.add(stage)
                await session.commit()
                await session.refresh(stage)
            
            logger.info(f"ğŸ’¾ å·¥ä½œæµé˜¶æ®µä¿å­˜æˆåŠŸ: {stage.id}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµé˜¶æ®µä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def get_workflow_stages(self, workflow_id: str) -> List[WorkflowStage]:
        """è·å–å·¥ä½œæµé˜¶æ®µåˆ—è¡¨"""
        try:
            async with self.async_session() as session:
                result = await session.execute(
                    select(WorkflowStage)
                    .where(WorkflowStage.workflow_id == UUID(workflow_id))
                    .order_by(WorkflowStage.order_index)
                )
                stages = result.scalars().all()
                return list(stages)
                
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥ä½œæµé˜¶æ®µå¤±è´¥: {workflow_id}, é”™è¯¯: {str(e)}")
            return []
    
    # ==================== å·¥ä½œæµè§’è‰²ç®¡ç† ====================
    
    async def save_workflow_role(self, role: WorkflowRole) -> None:
        """ä¿å­˜å·¥ä½œæµè§’è‰²"""
        try:
            async with self.async_session() as session:
                session.add(role)
                await session.commit()
                await session.refresh(role)
            
            logger.info(f"ğŸ’¾ å·¥ä½œæµè§’è‰²ä¿å­˜æˆåŠŸ: {role.id}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµè§’è‰²ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    # ==================== ä»»åŠ¡ç®¡ç† ====================
    
    async def save_task(self, task: Task) -> None:
        """ä¿å­˜ä»»åŠ¡"""
        try:
            async with self.async_session() as session:
                session.add(task)
                await session.commit()
                await session.refresh(task)
            
            # ç¼“å­˜åˆ°Redis
            await self._cache_task(task)
            
            logger.info(f"ğŸ’¾ ä»»åŠ¡ä¿å­˜æˆåŠŸ: {task.id}")
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def get_task(self, task_id: str) -> Optional[Task]:
        """è·å–ä»»åŠ¡"""
        try:
            # å…ˆä»ç¼“å­˜è·å–
            cached = await self._get_cached_task(task_id)
            if cached:
                return cached
            
            # ä»æ•°æ®åº“è·å–
            async with self.async_session() as session:
                result = await session.execute(
                    select(Task).where(Task.id == UUID(task_id))
                )
                task = result.scalar_one_or_none()
                
                if task:
                    await self._cache_task(task)
                
                return task
                
        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {str(e)}")
            return None
    
    async def update_task(self, task: Task) -> None:
        """æ›´æ–°ä»»åŠ¡"""
        try:
            async with self.async_session() as session:
                await session.merge(task)
                await session.commit()
            
            # æ›´æ–°ç¼“å­˜
            await self._cache_task(task)
            
            logger.info(f"ğŸ”„ ä»»åŠ¡æ›´æ–°æˆåŠŸ: {task.id}")
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡æ›´æ–°å¤±è´¥: {str(e)}")
            raise
    
    async def get_stage_tasks(self, stage_id: str) -> List[Task]:
        """è·å–é˜¶æ®µä»»åŠ¡åˆ—è¡¨"""
        try:
            async with self.async_session() as session:
                result = await session.execute(
                    select(Task)
                    .where(Task.stage_id == UUID(stage_id))
                    .order_by(Task.position_index, Task.created_at)
                )
                tasks = result.scalars().all()
                return list(tasks)
                
        except Exception as e:
            logger.error(f"âŒ è·å–é˜¶æ®µä»»åŠ¡å¤±è´¥: {stage_id}, é”™è¯¯: {str(e)}")
            return []
    
    # ==================== äº‹ä»¶ç®¡ç† ====================
    
    async def save_event(self, event: Event) -> None:
        """ä¿å­˜äº‹ä»¶"""
        try:
            async with self.async_session() as session:
                session.add(event)
                await session.commit()
                await session.refresh(event)
            
            # ç¼“å­˜åˆ°Redis
            await self._cache_event(event)
            
            logger.info(f"ğŸ’¾ äº‹ä»¶ä¿å­˜æˆåŠŸ: {event.id}")
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def get_event(self, event_id: str) -> Optional[Event]:
        """è·å–äº‹ä»¶"""
        try:
            # å…ˆä»ç¼“å­˜è·å–
            cached = await self._get_cached_event(event_id)
            if cached:
                return cached
            
            # ä»æ•°æ®åº“è·å–
            async with self.async_session() as session:
                result = await session.execute(
                    select(Event).where(Event.id == UUID(event_id))
                )
                event = result.scalar_one_or_none()
                
                if event:
                    await self._cache_event(event)
                
                return event
                
        except Exception as e:
            logger.error(f"âŒ è·å–äº‹ä»¶å¤±è´¥: {event_id}, é”™è¯¯: {str(e)}")
            return None
    
    async def update_event(self, event: Event) -> None:
        """æ›´æ–°äº‹ä»¶"""
        try:
            async with self.async_session() as session:
                await session.merge(event)
                await session.commit()
            
            # æ›´æ–°ç¼“å­˜
            await self._cache_event(event)
            
            logger.info(f"ğŸ”„ äº‹ä»¶æ›´æ–°æˆåŠŸ: {event.id}")
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶æ›´æ–°å¤±è´¥: {str(e)}")
            raise
    
    async def get_failed_events_for_retry(self, current_time: datetime) -> List[Event]:
        """è·å–éœ€è¦é‡è¯•çš„å¤±è´¥äº‹ä»¶"""
        try:
            async with self.async_session() as session:
                result = await session.execute(
                    select(Event).where(
                        Event.status == "failed",
                        Event.next_retry_at <= current_time,
                        Event.retry_count < Event.max_retries
                    )
                )
                events = result.scalars().all()
                return list(events)
                
        except Exception as e:
            logger.error(f"âŒ è·å–é‡è¯•äº‹ä»¶å¤±è´¥: {str(e)}")
            return []
    
    # ==================== äº‹ä»¶å¤„ç†å™¨ç®¡ç† ====================
    
    async def save_event_handler(self, handler: EventHandler) -> None:
        """ä¿å­˜äº‹ä»¶å¤„ç†å™¨"""
        try:
            async with self.async_session() as session:
                session.add(handler)
                await session.commit()
                await session.refresh(handler)
            
            logger.info(f"ğŸ’¾ äº‹ä»¶å¤„ç†å™¨ä¿å­˜æˆåŠŸ: {handler.id}")
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶å¤„ç†å™¨ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def update_event_handler(self, handler: EventHandler) -> None:
        """æ›´æ–°äº‹ä»¶å¤„ç†å™¨"""
        try:
            async with self.async_session() as session:
                await session.merge(handler)
                await session.commit()
            
            logger.info(f"ğŸ”„ äº‹ä»¶å¤„ç†å™¨æ›´æ–°æˆåŠŸ: {handler.id}")
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶å¤„ç†å™¨æ›´æ–°å¤±è´¥: {str(e)}")
            raise
    
    # ==================== äº‹ä»¶è®¢é˜…ç®¡ç† ====================
    
    async def save_event_subscription(self, subscription: EventSubscription) -> None:
        """ä¿å­˜äº‹ä»¶è®¢é˜…"""
        try:
            async with self.async_session() as session:
                session.add(subscription)
                await session.commit()
                await session.refresh(subscription)
            
            logger.info(f"ğŸ’¾ äº‹ä»¶è®¢é˜…ä¿å­˜æˆåŠŸ: {subscription.id}")
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶è®¢é˜…ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    # ==================== äº‹ä»¶è§„åˆ™ç®¡ç† ====================
    
    async def save_event_rule(self, rule: EventRule) -> None:
        """ä¿å­˜äº‹ä»¶è§„åˆ™"""
        try:
            async with self.async_session() as session:
                session.add(rule)
                await session.commit()
                await session.refresh(rule)
            
            logger.info(f"ğŸ’¾ äº‹ä»¶è§„åˆ™ä¿å­˜æˆåŠŸ: {rule.id}")
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶è§„åˆ™ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def get_event_rule(self, rule_id: str) -> Optional[EventRule]:
        """è·å–äº‹ä»¶è§„åˆ™"""
        try:
            async with self.async_session() as session:
                result = await session.execute(
                    select(EventRule).where(EventRule.id == UUID(rule_id))
                )
                rule = result.scalar_one_or_none()
                return rule
                
        except Exception as e:
            logger.error(f"âŒ è·å–äº‹ä»¶è§„åˆ™å¤±è´¥: {rule_id}, é”™è¯¯: {str(e)}")
            return None
    
    async def update_event_rule(self, rule: EventRule) -> None:
        """æ›´æ–°äº‹ä»¶è§„åˆ™"""
        try:
            async with self.async_session() as session:
                await session.merge(rule)
                await session.commit()
            
            logger.info(f"ğŸ”„ äº‹ä»¶è§„åˆ™æ›´æ–°æˆåŠŸ: {rule.id}")
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶è§„åˆ™æ›´æ–°å¤±è´¥: {str(e)}")
            raise
    
    async def get_active_event_rules(self) -> List[EventRule]:
        """è·å–æ¿€æ´»çš„äº‹ä»¶è§„åˆ™"""
        try:
            async with self.async_session() as session:
                result = await session.execute(
                    select(EventRule)
                    .where(EventRule.is_active == True)
                    .order_by(EventRule.priority.desc())
                )
                rules = result.scalars().all()
                return list(rules)
                
        except Exception as e:
            logger.error(f"âŒ è·å–æ¿€æ´»äº‹ä»¶è§„åˆ™å¤±è´¥: {str(e)}")
            return []
    
    # ==================== å·¥ä½œæµæ‰§è¡Œç®¡ç† ====================
    
    async def save_workflow_execution(self, execution: WorkflowExecution) -> None:
        """ä¿å­˜å·¥ä½œæµæ‰§è¡Œè®°å½•"""
        try:
            async with self.async_session() as session:
                session.add(execution)
                await session.commit()
                await session.refresh(execution)
            
            logger.info(f"ğŸ’¾ å·¥ä½œæµæ‰§è¡Œè®°å½•ä¿å­˜æˆåŠŸ: {execution.id}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œè®°å½•ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def get_workflow_execution(self, execution_id: str) -> Optional[WorkflowExecution]:
        """è·å–å·¥ä½œæµæ‰§è¡Œè®°å½•"""
        try:
            async with self.async_session() as session:
                result = await session.execute(
                    select(WorkflowExecution).where(WorkflowExecution.id == UUID(execution_id))
                )
                execution = result.scalar_one_or_none()
                return execution
                
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥ä½œæµæ‰§è¡Œè®°å½•å¤±è´¥: {execution_id}, é”™è¯¯: {str(e)}")
            return None
    
    async def update_workflow_execution(self, execution: WorkflowExecution) -> None:
        """æ›´æ–°å·¥ä½œæµæ‰§è¡Œè®°å½•"""
        try:
            async with self.async_session() as session:
                await session.merge(execution)
                await session.commit()
            
            logger.info(f"ğŸ”„ å·¥ä½œæµæ‰§è¡Œè®°å½•æ›´æ–°æˆåŠŸ: {execution.id}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œè®°å½•æ›´æ–°å¤±è´¥: {str(e)}")
            raise
    
    # ==================== çœ‹æ¿ç®¡ç† ====================
    
    async def save_board(self, board: Board) -> None:
        """ä¿å­˜çœ‹æ¿"""
        try:
            async with self.async_session() as session:
                session.add(board)
                await session.commit()
                await session.refresh(board)
            
            logger.info(f"ğŸ’¾ çœ‹æ¿ä¿å­˜æˆåŠŸ: {board.id}")
            
        except Exception as e:
            logger.error(f"âŒ çœ‹æ¿ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    async def save_board_column(self, column: BoardColumn) -> None:
        """ä¿å­˜çœ‹æ¿åˆ—"""
        try:
            async with self.async_session() as session:
                session.add(column)
                await session.commit()
                await session.refresh(column)
            
            logger.info(f"ğŸ’¾ çœ‹æ¿åˆ—ä¿å­˜æˆåŠŸ: {column.id}")
            
        except Exception as e:
            logger.error(f"âŒ çœ‹æ¿åˆ—ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    # ==================== ç¼“å­˜ç®¡ç† ====================
    
    async def _cache_workflow(self, workflow: Workflow) -> None:
        """ç¼“å­˜å·¥ä½œæµ"""
        try:
            key = f"workflow:{workflow.id}"
            data = workflow.to_dict()
            await self.redis.setex(key, self._cache_ttl, json.dumps(data, default=str))
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜å·¥ä½œæµå¤±è´¥: {str(e)}")
    
    async def _get_cached_workflow(self, workflow_id: str) -> Optional[Workflow]:
        """ä»ç¼“å­˜è·å–å·¥ä½œæµ"""
        try:
            key = f"workflow:{workflow_id}"
            data = await self.redis.get(key)
            if data:
                workflow_dict = json.loads(data)
                # è¿™é‡Œéœ€è¦å°†å­—å…¸è½¬æ¢å›Workflowå¯¹è±¡
                # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æœ‰å®Œæ•´çš„ååºåˆ—åŒ–é€»è¾‘
                return None  # æš‚æ—¶è¿”å›Noneï¼Œè®©å…¶ä»æ•°æ®åº“è·å–
            return None
            
        except Exception as e:
            logger.error(f"âŒ ä»ç¼“å­˜è·å–å·¥ä½œæµå¤±è´¥: {str(e)}")
            return None
    
    async def _remove_cached_workflow(self, workflow_id: str) -> None:
        """ä»ç¼“å­˜ç§»é™¤å·¥ä½œæµ"""
        try:
            key = f"workflow:{workflow_id}"
            await self.redis.delete(key)
            
        except Exception as e:
            logger.error(f"âŒ ä»ç¼“å­˜ç§»é™¤å·¥ä½œæµå¤±è´¥: {str(e)}")
    
    async def _cache_task(self, task: Task) -> None:
        """ç¼“å­˜ä»»åŠ¡"""
        try:
            key = f"task:{task.id}"
            data = task.to_dict()
            await self.redis.setex(key, self._cache_ttl, json.dumps(data, default=str))
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    async def _get_cached_task(self, task_id: str) -> Optional[Task]:
        """ä»ç¼“å­˜è·å–ä»»åŠ¡"""
        try:
            key = f"task:{task_id}"
            data = await self.redis.get(key)
            if data:
                # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æœ‰å®Œæ•´çš„ååºåˆ—åŒ–é€»è¾‘
                return None
            return None
            
        except Exception as e:
            logger.error(f"âŒ ä»ç¼“å­˜è·å–ä»»åŠ¡å¤±è´¥: {str(e)}")
            return None
    
    async def _cache_event(self, event: Event) -> None:
        """ç¼“å­˜äº‹ä»¶"""
        try:
            key = f"event:{event.id}"
            data = event.to_dict()
            await self.redis.setex(key, self._cache_ttl, json.dumps(data, default=str))
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜äº‹ä»¶å¤±è´¥: {str(e)}")
    
    async def _get_cached_event(self, event_id: str) -> Optional[Event]:
        """ä»ç¼“å­˜è·å–äº‹ä»¶"""
        try:
            key = f"event:{event_id}"
            data = await self.redis.get(key)
            if data:
                # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æœ‰å®Œæ•´çš„ååºåˆ—åŒ–é€»è¾‘
                return None
            return None
            
        except Exception as e:
            logger.error(f"âŒ ä»ç¼“å­˜è·å–äº‹ä»¶å¤±è´¥: {str(e)}")
            return None
    
    # ==================== ç§æœ‰æ–¹æ³• ====================
    
    async def _init_redis(self):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        try:
            import os
            redis_url = os.getenv("REDIS_URL", "redis://localhost:6379")
            self.redis = redis.from_url(redis_url, decode_responses=True)
            
            # æµ‹è¯•è¿æ¥
            await self.redis.ping()
            logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ Redisè¿æ¥å¤±è´¥: {str(e)}")
            raise
    
    async def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            import os
            database_url = os.getenv(
                "DATABASE_URL", 
                "postgresql+asyncpg://user:password@localhost/kaiban_db"
            )
            
            self.db_engine = create_async_engine(
                database_url,
                echo=False,  # ç”Ÿäº§ç¯å¢ƒè®¾ä¸ºFalse
                pool_size=10,
                max_overflow=20
            )
            
            self.async_session = sessionmaker(
                bind=self.db_engine,
                class_=AsyncSession,
                expire_on_commit=False
            )
            
            logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            raise 